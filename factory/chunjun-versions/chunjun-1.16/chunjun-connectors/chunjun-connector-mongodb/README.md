```markdown
Python数据结构数据分析架构师SQL
职位描述：
1、负责蚂蚁链商业支撑中台数据体系设计与研发，包括统一离线／实时数据架构，以及公共数据层、辅助决策、赋能小二、助力业务等数据研发工作；
2、负责业务领域核心数据体系的规划设计，在数据技术上，能结合业界领先技术进行探索，在数据化运营和数据能力产品化上，制定数据技术和服务的策略，负责用户标签体系、数据智能化、自动化体系和实时数据体系等体系建设；
3、负责数据资产管理，包括架构规范、安全合规、质量风险、容量成本、研发效能等主要领域，对负责领域进行问题的识别分析、抽象解决方案并持续推动管理目标达成；
4、负责数据质量、安全性、稳定性等数据管理，建立打通各业务、产品团队的统一数据标准、规范、协作机制，让数据获取更高效、精准。
职位要求：
1、有至少5年以上大数据开发及架构经验，熟悉ODPS相关数据开发技术栈，有丰富的海量数据性能处理经验；
2、丰富的数据平台架构经验，熟悉数据仓库建模及ETL设计开发；
3、具备一定的Java或Python语言开发能力，具备基础机器学习算法知识尤佳；
4、快速理解业务方的需求，以及业务方的业务闭环及相关核心指标，能从海量数据提炼核心结果，发现和分析其中隐含的变化和问题，并能够为业务方提供数据的解决方案；
5、具备创新精神，良好的逻辑思维和语言表达能力、善于编写高可读性的文档；
6、有大型数据中台架构及管理经验优先，有区块链领域经验优先，有业务中台领域经验优先。									
									
									
									
									
									
									
									
									
									
1. 候选人至少对以下某一方面有丰富实战经验或良好的技术深度：
A. 数据治理方向：熟悉数据治理方法论，对数据建模、数据质量、数据资产、元数据管理等有实战经验；
B. 技术架构方向：熟悉大数据产品和技术，熟悉ETL的开发和流程优化，对数据采集、数据集成、数据开发、数据分析等大数据领域有实战经验；
C. 算法应用方向：熟悉大规模数据挖掘、机器学习、深度学习等相关技术，对分类聚类等机器学习算法、TensorFlow/Caffe等深度学习框架有实战经验；
D. 大数据基础技术方向：熟悉大数据产品生态圈包括但不限于Hive、HBase、Kafaka、Flink、ES、Spark等， 善于容量规划、架构设计和性能优化并有丰富实战经验；
2. 5年以上大数据技术相关工作经验，有产品定义或研发管理能力优先，有交通、电力、能源、制造等垂直行业经验优先；
3. 具有良好的项目交付与团队协作能力，能够组织跨团队协作、推动项目落地；
4. 有强烈的主人翁意识，有积极主动帮助客户成功的意愿和热情，并爱好挑战；									
									
									
									
									
									
									
									
									
									
工作职责:
1、参与数据中台、大数据平台等相关产品体系建设，包括需求、架构、研发等过程；
2、结合原始业务需求，进行需求分析分解、系统设计、文档编写、模块分解、核心编码及Review等工作；
3、主导产品疑难问题解决、性能优化和质量提升；
4、持续支撑产品技术突破和业务创新、探索，并赋能团队成员。
任职资格:
1、全日制本科及以上学历，计算机相关专业，5年及以上大数据领域工作经验；
2、熟练掌握Java语言，掌握Spring Boot、Spring Cloud、Netty等框架，掌握面向对象编程思想；
3、至少符合以下一条或多条标准：
1）具备数据治理、数据中台类产品的设计与开发经验：
   如数据ETL工具、数据质量平台、数据标准平台、元数据管理平台、数据资产与服务平台、数据安全管理、标签管理平台、数据开发套件等的至少一种；
2）具备大数据存储与计算框架的开发与使用经验：
   如Hadoop、Hive、Yarn、Spark、Flink、Presto（Trino）、Iceberg、Hudi等的一种或多种；
3）熟悉数仓领域知识和设计经验：
   如数仓建模方法、海量数据ETL开发、SQL使用与调优等，或具备数据挖掘经验；
4、熟练使用UML工具，具备良好的文档编写能力；
5、熟悉Linux系统、Shell脚本，理解和掌握TCP/IP、HTTP等网络基础知识；
6、熟悉Docker、K8S，有基于容器平台进行企业级分布式系统部署和实践经验者优先；
7、有以下相关产品设计、开发和深度使用经验者优先：Dataworks、Dataphin、EMR、MaxCompute、FusionInsight MRS、DAYU等；
8、责任心强，做事认真细致，自我驱动，具备良好的逻辑思维和沟通表达能力，团队合作和抗压能力强。									
									
									
									
									
									
									
									
									
									
岗位职责：
1、负责大数据产品设计工作，负责产品的核心模块开发、关键问题处理等工作
2、参与项目需求分析、系统架构设计、方案评审等工作
3、参与基础框架研究、输出技术分享和培训、提升团队技能等相关工作
岗位要求：
1、本科及以上学历，计算机相关专业，5年及以上实际Java开发经验，985/211优先
2、具有3年及以上的架构设计经验，熟悉分布式系统、负载均衡的设计和应用，对消息服务、负载均衡、高可用机制等有深入理解
3、精通Java语言，熟悉多线程、网络编程，对JVM有深入理解，具有设计实现高并发、高可用的Java应用的能力并对现有系统进行调优
4、熟悉常用中间件，理解其设计原理
5、熟悉大数据基础组件技术原理，有Spark、Flink引擎开发经验者优先
6、熟悉数据治理相关理论，有数据数据治理工作经验者优先
7、具有较好的开源项目学习能力，良好的英文文档阅读能力，具有修改开源项目源码实际经验者优先
8、良好的沟通经验和团队合作能力，优秀的文档编写能力，热爱技术，良好的学习习惯，并勇于承担风险和挑战									
									
									
									
									
									
									
									
									
									
岗位职责：
1、负责大数据平台的规划、开发、部署、监控、优化等工作；
2、企业级数据中台，数据分析和数据服务体系的开发和建设；
3、与业务、产品、研发等紧密合作，深度挖掘大数据应用需求，结合平台特点，制定数据架构。
任职资格：
1、 本科及以上学历，3年以上大数据处理研发经验，精通hadoop、Hbase、Hive等技术，熟悉 flink、spark streaming等流式框架中的一种或多种；
2、有数据平台开发经验，包括但不限于离线开发平台、数据质量中心、元数据管理、数据资产管理，实时流平台等；
3、5年以上java开发经验，熟练springboot框架开发，有系统或独立模块设计经验，熟练应用mysql、redis等；
4、熟练掌握linux操作系统常见命令， trouble-shooting 的经验和能力；
5、清晰的逻辑分析和表达能力，好的团队精神和合作意识，强烈的责任心；
6、有基于大数据分析推动业务提升或优化的实际案例，有数据挖掘、机器学习经验者优先考虑；
7、具有强烈的责任感和自驱精神。									
									
									
									
									
									
									
									
									
									
大数据模型架构师
工作年限：五年以上
学历要求：硕士
期望层级：P7-P8
职位描述：
1、负责数据平台和大型数据集市整体框架规划和规范体系的完善优化，推动实施落地； 
2、负责数据平台和数据资产管理产品化的规划和落地； 
3、负责结合阿里巴巴BSBSC业务，设计创新型数据模型和应用解决方案，团队技术分享与引导和前瞻性技术研究。
岗位要求：
1、计算机、数学、统计或相关专业硕士及以上学历，五年以上工作经验，具有大型系统的技术架构\应用架构\数据架构的的研发经验； 
2、精通数据仓库各类建模理论，以及数据仓库数据层级关系， 精通 schema evolution的方式方法，熟悉 Json, Avro, PB, Thrift 等大数据schema。
3、熟悉业界主流数据仓库模型设计方案，有丰富的分布式计算平台模型架构（Hadoop, Hive, HBase,ZooKeeper, Spark, Cassandra, MapReduce）经验； 
4、具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验； 
5、具备良好的数据标准(指标管理、模型管理、质量管理)管理与推广经验； 
6、管理过数据量上PB级别，节点数1000以上的大数据集群，开发，优化并管理过上PB级别的大数据作业
7、具有良好的产品sense，商业到技术数据映射能力； 
8、具有良好的沟通、团队协作和推动落地能力；愿意专注于数据平台/数据模型领域。									
									
									
									
									
									
									
									
									
									
团队介绍：
负责大淘系用户增长，探索手淘的增长方法论及增长平台，打造智能数据驱动用户增长引擎，支撑集团多APP矩阵增长
岗位描述：
1. 构建大淘宝用户标签体系设计，负责数据建模、海量数据架构设计，开发与性能优化
2. 对用户基础数据、实时状态数据进行数据平台建设，为业务场景提供数据服务和洞察分析能力
3. 通过专题分析，对用户及业务问题进行深入分析，为用户增长提供数据支持
4. 沉淀分析思路与框架，提炼数据产品需求，与相关团队（如技术开发团队）协作并推动产品的落地
5. 与相关团队协作进行数据建模和快速迭代，推动数据驱动增长落地，负责业务中台的设计和落地，降低数据使用成本，让数据赋能业务
岗位要求：
1. 计算机、统计学或其它相关专业硕士及以上学历，至少3年的数据开发与分析经验；
2. 精通数据仓库领域知识和管理技能，包括但不限于：元数据管理、数据质量、主数据管理、性能调优等；
3. 有丰富的数据分析、挖掘、清洗和建模的经验，具有较强的数据整合，数据分析/挖掘和解决业务问题的能力，能从海量数据提炼核心结果，及时发现和分析其中隐含的变化和问题；
4. 具备大数据的处理能力，有storm/spark/flink等开发经验者优先；
5. 具备良好的沟通和自我驱动力，有项目管理经验及用户增长经验优先。									
									
									
									
									
									
									
									
									
									
岗位职责：
1.负责滴滴PB级一站式OLAP平台建设、引擎研发工作，支持公司日益增长的海量数据分析需求；
2.负责OLAP团队管理工作，构建良好的梯队，持续提升团队技术能力；
3.负责OLAP业务沟通工作，为业务提供解决方案，主动帮助业务成功。
岗位要求：
1、至少精通一种OLAP技术，如ClickHouse、Druid、Doris等，并有大规模实践经验；
2、3年以上团队管理经验，善于培养新人；
3、善于帮助业务找到合理解决方案，以成就业务为己任；
4、积极参与开源社区贡献者优先；
5、有良好的跨团队沟通协调能力。									
									
									
									
									
									
									
									
									
									
参与公司大数据平台和数据中台建设，包括但不限于数据研发平台，数据集成，数据资产管理，数据安全，实时计算等
欢迎有2b经验丰富的同学加入！									
									
									
									
									
									
									
									
									
									
P7/P8岗位，海量HC，欢迎来撩~~
我们的部门是阿里巴巴数据技术及产品部，定位于阿里集团数据中台，为阿里生态内外的业务、用户、中小企业提供全链路、全渠道的数据服务。作为阿里大数据战略的核心践行者，致力于让“大数据，赋能商业，创造价值”。
《大数据之路-阿里巴巴大数据实践》是我们阶段性的理论沉淀，欢迎数据技术爱好者与我们共同讨论和建设！
岗位描述：
1、参与阿里巴巴大数据平台和数据中台建设，承担大数据智能研发平台整体架构工作
2、参与建设和输出国内顶尖的云上数据中台一站式商业解决方案，承载百亿级商业化目标的落地实施
3、在传统大数据开发和数仓建模的基础上，探索创新的方案，构建自动化、智能化的建模引擎
4、工作范围涉及包括但不限于：高并发分布式系统，智能指标建模，智能数据服务，数据资产管理，大规模商业化，流批一体技术等领域
岗位要求：
1、熟练使用常用的JAVA技术框架，并对JAVA Web的各种主流框架如Spring、SpringBoot、MyBatis等有深入的应用和优化经验，掌握它的原理和机制
2、精通一种或多种大数据相关组件技术，比如：Flink，Spark，Hive，HBase，调度系统，权限系统，元数据管理系统，搜索引擎技术等，对相关组件的架构原理有深入的了解
3、熟练掌握微服务开发和架构设计，有大型复杂业务系统架构设计经验者优先									
									
									
									
									
									
									
									
									
									
工作内容：
-负责公司基础数据平台规划和架构，支持海量数据的实时和离线分析；
-理解业务场景、产品逻辑和分析需求，规划各种数据间的关联关系;
-负责数据仓库模型在Hadoop及数据库的实现和优化以及ETL流程设计及优化、数据质量管理；
-管理团队，培训团队成员，营造良好团队气氛。
岗位要求：
-本科及以上学历，计算机、数学相关专业，5年以上PB级别以上数据中台项目设计开发经验;
-丰富大数据架构和开发经验，熟悉数仓领域和数据开发，具备大型数据仓库、ETL架构设计模型设计经验；
-掌握一定数据结构，算法，对大规模数据开发有丰富实战经验，熟练scala,java ,python,go编程；
-熟悉hadoop分布式计算，精通Hadoop生态组件，对spark、flink、kafka、 hbase等实践经验；
优先条件：
-熟悉业界有影响力的数据仓库和大数据领域产品，解决方案和技术，熟悉OLAP引擎， 具备实时流计算大数据项目经验优先；
-有大型流量型产品大数据架构设计优先。									
									
									
									
									
									
									
									
									
									
岗位职责：
1、参与公司大数据平台和数据中台的架构设计和建设，承担相关服务、平台、产品的技术架构设计和研发工作，打造面向未来、业界一流的大数据技术；
2、参与建设业内领先的大数据技术解决方案，驱动业务发展突破，同时满足稳定性、安全合规、数据质量、成本效能等方面的严苛要求；
3、团队工作范围涉及但不限于：数据研发平台，智能建模，数据集成，数据资产管理，数据安全隐私合规，数据质量，实时计算，web数据采集挖掘，任务和资源调度系统等等。
任职要求：
1、全日制本科及以上学历，计算机等相关专业毕业，5年以上相关工作经验；
2、工作思路清晰，较好的沟通能力和技术学习能力，拥有良好的编码习惯，有很强的自学能力和自我提高的愿望；
3、计算机和JAVA基础扎实，熟悉JVM、IO、多线程、并发、网络、数据库等，理解面向对象、设计模式、分布式等相关技术；
4、熟练使用主流JAVA技术栈框架，如Spring、SpringBoot、MyBatis、Netty等；
5、熟悉一种或多种大数据相关技术如：Hadoop、Flink、Spark、Hive、Storm、搜索引擎技术等优先。									
									
									
									
									
									
									
									
									
									
岗位职责
带领大数据平台团队，负责实时、离线数据分析处理或流式计算的研究及通用平台的建设，以及创新性技术方案的开发与验证。
1. 负责大数据平台资源规划、权限控制、运维架构设计，为各产品业务提供稳定、高效、安全的运行环境；
2. 负责基于海量数据采集、存储、治理及服务方案的技术选型及架构设计；
3. 负责实时，离线数据分析处理及实时平台的建设和搭建；
4. 从整体技术架构角度协助并推动战略落地，开发大数据平台的核心代码；
5. 负责产品研发过程中的技术架构设计、数据处理逻辑等方面文档的沉淀与积累。 参与研发团队的日常技术交流与分享，为其他同事提供技术指导与帮助；
6. 深入研究大数据前沿技术和产品，与业界先进技术保持同步。
岗位要求
1. 统招计算机相关本科以上学历，有5 年以上大数据平台领域工作经验；
2. 精通大数据相关组件技术，包括但不限于DataX/Canal、 Hadoop体系、Flink、OLAP、调度系统、权限系统等，理解其内部原理和适用场景，了解核心源码及调优方法；
3. 熟练运用Java和Python，熟悉分布式系统的设计和应用，熟悉数据库、缓存、消息队列、RPC
等内部机制；
4. 有实际的大数据工程平台建设实践经验，在 ETL 开发和大数据集成、数据开发等领域有实战经验；
5. 有强烈的主人翁意识，能适应一定工作压力，并有较强沟通能力和理解能力，有一定的团队管理能力；
6. 有大数据中台建设经验、数据治理经验或出行大数据从业经验者优先。									
									
									
									
									
									
									
									
									
									
● 岗位职责：
1. 负责大数据相关商业化产品的技术方案制定、开发人员工期安排、产品交付技术验收
2. 负责大数据实时计算的技术架构、基础建设、性能优化、稳定性提升等，并与离线部分做好协同和互补
3. 深入了解业务并参与公司数据产品的设计和研发，包括内部的数据产品（面向产品和运营）和对外的数据产品（面向B端电商企业为主）
4. 带领大数据开发同学（实时计算为主），进行技术学习和提升，把控同学的开发质量和进度，阶段性Review技术方案和代码
5. 负责跨部门大数据实时相关数据支持，包括合作项目的技术方案输出、评审，技术难点的讨论、落地和工作分配等
● 岗位要求：
1. 本科及以上学历，5年以上大数据工作经验，3年以上团队管理经验，具备卓越的数据架构和业务抽象能力
2. 具备丰富的大数据平台架构和研发经验，熟悉数据采集、清洗、同步、计算、存储、应用等各个环节，拥有设计和构建大数据实时链路的能力，同时对于大数据离线相关熟悉的优先考虑
3. 熟练使用Flink、Spark、Storm、Hbase、Hadoop、Hive SQL等大数据组件，熟悉阿里云RDS、PolarDB、DataWorks、Hologres、Kafka、ADB for Postgre SQL等数据套件和解决方案的优先
4. 至少3年以上的Java开发经验，同时熟悉Python更佳
5. 有一定的电商行业背景，有ToB企业服务软件开发经验优先
6. 具备一定的商业洞察能力和数据分析能力，有数据挖掘和机器学习经验的优先，有数据产品设计经验的优先
7. 丰富的跨团队协同的经验，有一定的管理团队和培养人员的经验，善于沟通、乐于分享
● 团队简介：
同学你好：
我是聚水潭大数据团队的负责人，我真诚的期望你能够在看完岗位介绍后，可以了解一下我们的团队以及文化。
大数据团队主要有以下几个角色组成：数据产品经理（业务方向）、数据产品经理（商业分析方向）、Java后端（业务方向）、Java后端（中间件和中后台方向）、大数据开发（离线为主）、大数据开发（实时为主）、大数据开发（架构为主），同时大数据团队的业务协同部门主要有大前端（前端资源）、测试团队（测试资源）、运维团队（运维资源）。
聚水潭作为一家电商SaaS协同平台，公司的商业模式是基于ERP为核心的电商企业服务平台，因此大数据团队也是以业务为导向并且注重用技术能力、产品创新来实现高效率、低成本的电商企业数据服务的支持，我们团队有对于电商企业运作模式比较熟悉的产品经理，有对于云原生比较精通的来自于阿里等大厂的优秀技术人员，也有技术功底扎实、架构能力不错的架构师和小组长。
大数据团队的学习氛围比较浓重，包括业务的理解和技术的学习都会互相交流、互相帮助、定期分享，工作模式相对自由，在大方向上做到思想统一后，具体的工作尽量由同学自己来思考、设计、推进、落地，遇到困难和阻塞可以求助于同学或者主管，大家一起出谋划策解决问题。我们期望基于一定的自由度和较高的求知欲的工作环境营造，让团队每个成员成为一个勤于思考、善于协同、乐于分享、目标导向的优秀青年。
因此也期望有意向加入我们的你，是一个不甘于按部就班工作、喜欢创造、喜欢挑战、乐于分享、乐于助人、积极思考、做事踏实的同学，我们今天在做一件电商企业数字化的事情，其实我们中国的电商企业的数字化进程还处于初级阶段，其中有大量的机会和机遇，数字化做好了，企业效率就能提升，企业活得更好了，就能创造更多就业机会，对于社会稳定、经济发展都是一件有普世价值的好事儿。
欢迎优秀的你投递简历，期望有机会与你一同为电商企业数字化的事业尽一份力~
● 公司简介：
聚水潭是一家以SaaS软件和toB企业服务作为核心产品的公司，目前公司员工数量达到3000+人，服务商家数量达到100+万家，主要产品有聚水潭ERP、分销ERP、跨境ERP、聚胜算、数据中台、聚货通、聚货选、聚经销、聚店长等，对接了淘宝、天猫、1688、AliExpress、抖音、快手、京东、拼多多、唯品会、苏宁易购、有赞、考拉、得物、云集、爱库存、好衣库、小红书、有货、Ebay、Shopee、Shopify等等300+多家电商平台，是SaaS ERP领域的龙头企业，当前已经完成C轮融资，投资机构包括：高盛、红杉、元璟、蓝湖、中金、微光、嘉海基金、阿米巴基金等
公司拥有完善的薪酬福利制度和非常开放的激励制度，除了基本的月薪和餐补之外，还有季度奖励（0.2~1个月的月薪）和年终奖励（2个月~20个月的月薪），公司重视人才的引入和培养，不吃大锅饭，除了充分激励突出贡献者之外，还给大家创造了非常好的学习环境，包括内部培训、外派培训、行业峰会、产品和技术交流等等，管理层来自阿里、腾讯、网易、亚马逊等知名大厂，不仅会分享产品、技术和管理方面的干货，而且还会邀请各大知名互联网公司的牛人过来做交流
公司的组织架构非常扁平，技术牛人和业务达人致力于带领一线员工迅速成长，公司的氛围开放透明，让每一位员工充分理解工作的价值和背后的业务逻辑，团队的每一位成员都是业务的共创者和贡献者，同时重视员工的时间管理，不提倡低效和无效的加班，期望通过提升技术能力和管理能力来提高工作效率和业务进度，同时给予大家更多的时间去自我学习和个人提升
100万+的企业客户，PB级别的海量数据，巨大的供应链市场，期待你的加入，一起来创造toB领域的奇迹！~									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
任职要求：
负责实时、离线数据分析处理或流式计算的研究及通用平台的建设，以及创新性技术方案的开发与验证
1、负责大数据平台资源规划、权限控制、运维架构设计，为各产品业务提供稳定、高效、安全的运行环境；
2、负责实时，离线数据分析处理及实时平台的建设和搭建
3、熟悉 Flink 流式计算引擎的使用以及源码原理，并且有相关的流式处理平台的经验。
4、Java基础扎实，熟练掌握垃圾回收，网络，多线程编程，了解 python 或 scala
5、负责大数据平台技术架构、数据架构的分析与设计；
职位要求：
1、本科及以上学历，5年以上工作经验，3年以上大数据领域工作经验，熟悉java、spark；
2、熟悉开源大数据平台如Hbase、ES、Kylin、tidb等，有实际的报表平台、多维度分析工具、ETL平台、调度平台中至少一种工具的实际建设经验；
3、有上述相关系统为基础的实际成功的复杂系统项目的架构和开发经验；
4、热爱开源技术，熟悉一种或者多种大数据生态技术（Flume，Kafka、Hive、Hbase、Spark、Storm、Hadoop、Flink等），熟悉源码者优先；
5、相关开源领域的活跃贡献者或大型互联网公司相关从业经验者优先；
6、了解flink的源码，使用过Flink做实时计算平台优先。
有机会接触千亿级海量数据的离线和实时的数据处理，涉及Java,Spark,Hive,Spark streaming,Hbase,Elasticsearch,Flink等大数据的前沿技术和多云的统一架构。									
									
									
									
									
									
									
									
									
									
岗位描述：
1、负责公司整体大数据架构以及团队管理，包括大数据核心方案设计、团队搭建、人员培养以及人才梯队建设等；
2、有很好的业务sense，能够配合业务团队解决在业务高速发展中遇到的数据问题；
3、负责在数据方向遇到的技术问题攻坚，开放性的解决公司内部的数据治理、数据存储、数据传输、数据展示、数据分析等多维度的数据问题；
4、深度理解各个业务方向数据诉求，负责大数据体系建设，构建行业的数据基础设施和数据应用体系；
5、负责新技术的预研和引入推广，前瞻性的规划未来大数据的发展，面向未来的智能大数据产品、技术创新突破，高效赋能业务；
任职资格:
1、全日制本科及以上学历，计算机相关专业，3年以上团队管理经验；
2、熟悉大数据生态，有很强的数据 sense，可以在复杂问题中快速找到解决方案；
3、熟悉数据领域，尤其是企业级的数据仓库、数据分析的相关工作，优秀的架构设计能力；
4、精通Spark、Hadoop、Flink等，精通至少其中四种HDFS、Yarn、Hbase、Hive、 Kafka、Redis、Flume、kylin等，并具有丰富的大数据平台应用研发经验；
5、深刻理解大数据处理（流计算，分布式计算，分布式文件系统，分布式存储等）相关技术和实现方法；
6、熟悉Spark、Hadoop、Flink相关框架源码者优先，掌握Linux操作系统；
7、善于发现问题并解决问题，具备吃苦耐劳的敬业精神和团队合作精神，有很强的积极主动性、沟通能力、领导能力，搭建团队能力，自驱力强，有实现数据价值的热情和追求。									
									
									
									
									
									
									
									
									
									
1、负责各类数据体系的实时数仓建设，通过数据＋工程化，赋能业务，提供全链路、可分析的业务服务能力；配置化、可复用的数据技术能力；更直观、更具指导性的产品化能力。
2、建设集团核心的实时数据资产，利用数据、分析、技术、产品化等能力，为集团重点业务场景提供数据服务化、数据业务化的整套数据及产品解决方案
3、建设数据稳定性体系，建设丰富的技术＋业务元数据，完善数据引l擎和服务；结构化业务场景，抽象通用业务逻辑，沉淀可复用的数据洞察能力，通过模版化和组件化提升数据架构扩展性，从而支持数据产品的快速迭代和横向扩展
4、研发实时OLAP（开源的Starrocks, Elasticsearch, Druid, ClickHouse)赋能业务，构建实时数仓									
									
									
									
									
									
									
									
									
									
岗位职责：
1.建设和培养公司大数据团队，包括大数据基础建设和数据分析挖掘团队；
2.带领团队，负责公司大数据平台、数据中台、BI系统的规划、建设与交付，包含数据采集规范、数据仓库等基础设施建设，技术核心攻坚；
3.带领团队，负责公司数据挖局，分析业务、商业、人岗匹配数据模型，对各端（技术/产品/业务）数据能力输出；
4.负责建立和维护大数据平台技术标准规范、采集规范、数仓规范，建设数据采集评估标准；
5.负责监控大数据产品数据，提升整体产品的用户满意度，分析运营数据，完善产品并不断改进用户体验和提出优化建议等。
 
职位要求：
1.本科及以上学历，8年及以上大数据、BI开发经验，3年以上团队管理经验，对数据分析领域有较强理解，主导设计过数据分析、数据挖掘相关产品，深入了解主流大数据技术、产品的现状和发展趋势；
2.较深入地了解基于Hadoop生态的大数据系统及传统数据仓库技术，例如hive、hbase、storm、kafka,、spark、flink等等，具备良好的大数据平台架构设计能力；
3.具备数据建模和分析经验，熟悉数据挖掘、机器学习、智能推送等常用算法；
4.对数据敏感，条理清晰，具有较强的分析问题和解决问题的能力；
5.有消费金融，金融科技行业等大型互联平台大数据或数据中台产品、项目经历。
要求：
1）互金加分，电商行业
2）从0-1经验加分项
3）独当一面 底层再到应用层。									
									
									
									
									
									
									
									
									
1、 负责数据仓库逻辑模型和物理模型设计；
2、 参与数据产品设计和评审，保障数据架构稳定；
3、 负责生产系统数据源调研和接口分析；
4、 指导和协助团队内其他成员，共同建立起商业智能分析工作的流程、规范和方法；
5、 完成公司安排的其他数据相关工作和任务；
任职资格
1.本科以上学历，有7年左右DW/BI项目实施和开发经验，5年以上数仓模型设计经验；
2. 熟悉数据仓库各类建模理论，以及数据仓库数据层级关系，精通3NF和多维数据模型设计，具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验；
3.至少熟练使用Shell、Python等脚本语言之一；
4.优秀的协调沟通与团队协作能力，愿意专注于技术研发；
5.有元数据管理、数据质量管理、主数据管理经验者优先；
6.精通Spark、Hive的编程模型并熟练使用，精通SQL，有较好的SQL性能调优经验；									
									
									
									
									
									
									
									
									
岗位职责：
1、负责公司大数据平台的整体规划，技术路线，系统架构设计、开发和实现；
2、设计并优化大数据架构，包括数据采集、数据治理、数据安全、 数据仓库、数据应用、算法应用等；
3、深入了解实际业务，与业务部门高效配合，通过数据分析、数据挖掘、机器学习等各种方法挖掘数据价值，不断完善数据预测、运营支持、营销应用、决策支撑等相关体系；
4、主动发掘更多大数据团队的潜力及价值，实现更强的数据支撑和数据驱动能力；
5、负责大数据团队成员的工作管理及能力提升，把控前瞻性的技术方向以支撑未来业务发展。
任职要求：
1、全日制本科及以上学历，8年以上大数据开发工作经验，3年以上技术管理经验，有电商行业经验；
2、精通Hadoop、Flink、Kafka、Spark、Redis、Hive、Elastic Search等大数据相关技术，并能结合业务场景进行架构设计和模型建设，参与或主导过大数据分析项目，有大型互联网分析项目经验者优先；
3、精通数据仓库和ETL的设计与开发，熟悉TensorFlow、Pytorch等不同机器学习平台，了解机器学习各种算法；
4、喜欢尝试新技术，关注新的技术方向，能够平衡好业务的需求和技术团队成长之间的关系，并能从技术趋势和设计思路上辅助产品工作；
5、良好的沟通协调能力、团队协作能力、解决问题能力；
6、自我驱动能力强，踏实勤勉，对有挑战的问题充满激情。									
									
									
									
									
									
									
									
									
职位描述
1、负责京东零售实时数据产品线建设； 
2、深入理解并抽象业务需求，解决数据全链路问题，发挥数据价值。
职位要求
1、对hadoop/yarn/hive等大数据工具有使用经验，熟悉大数据存储系统hbase/hdfs等，了解背后的实现原理
2、具备大数据实时开发能力，精通 Storm/Flink/Kafka/ElasticSearch/Clickhouse/Druid 等主流大数据技术栈（不要求全部精通）； 
3、具备复杂实时流端到端问题解决能力和优化经验； 
4、参加过大规模数据项目，有PB级海量数据处理经验者优先；									
									
									
									
									
									
									
									
									
岗位职责：
1、负责腾讯云实时计算平台Oceanus的开发与设计；
2、负责腾讯云实时计算平台Flink内核生态的开发与设计。
岗位要求：
1、本科及以上学历，计算机相关专业，3年以上相关工作经验; 
2、熟悉 Linux 开发环境，精通Java/Golang/C++一种或多种编程语言 ； 3、扎实的数据结构，算法和编程功底，有良好的编程习惯和风格; 
4、有SQL引擎优化开发，比如Apache Calcite/SparkSQL/Beam等项目经验者优先； 
5、熟悉TCP/IP协议栈，具有TCP/UDP网络编程相关经验; 
6、熟悉Flink计算引擎底层原理、有Flink内核或者Connector开发经验者优先； 
7、在Flink社区有代码提交者或者Committer者优先 ；
8、熟悉K8S和Docker等容器技术者优先; 
9、优秀的分析问题、解决问题能力和团队合作意识、有良好的责任心、善于沟通、工作上能自主驱动、用于接受挑战、富有创新精神; 
10、通过腾讯云技术认证或同等资格认证的优先录取 通过腾讯云从业资格证或同等资格认证的优先录取。									
									
									
									
									
									
									
									
									
工作职责:
 1、负责公司整体基础数据建设(涵盖社区、电商、广告等业务方向)，提供通用，稳定，丰富、高效的公共数据能力，提升数据支持业务的效率，探索数据 的增量价值;
2、面向社区、电商、广告等业务方向，建设专题数据，提供丰富易用的数据服务，直接支持公司业务决策分析，赋能业务;
3、建设公司全站数据治理和管理体系，结合业务+元数据+技术，推进资源成本的优化，提高数据服务的数据质量，保障数据产出的稳定性。
任职资格: 
1、本科及以上学历，3年以上数据研发经验;
2、有较为丰富的数据仓库研发经验，熟悉数据仓库、数据体系和数据价值的建设及优化;
3.掌握数据管理治理的相关理论，熟悉数据治理，数据标准，企业级数据建模，主数据，元数据管理等方法论:
4、熟悉大数据架构，具备实时或离线数据研发能力，熟悉Hive，KafkaSpark，StormHbaseFlink等相关技术并有相关开发经验
5、具备快速学习能力、跨团队沟通协作能力，有较强的逻辑思维能力和解决问题能力。									
									
									
									
									
									
									
									
									
工作职责
1、统筹和规划数据管理类相关工具和系统。
2、负责研究与落地和数据开发相关的工具、平台，提高团队数据开发的效率和能力；
3、探索数据、分析业务领域内的痛点，并与业务沟通，提出相应的解决方案。
任职资格
1、统招全日制本科以上学历, 计算机专业优先，5年以上大数据开发工作经验。
2、具有丰富的数据类项目开发交付经验，主导项目整体架构设计和管理过程的工作。
3、具备熟练Java开发经验，熟悉微服务框架、中间件、分布式技术等。
4、熟悉Flink、Spark、HBase、Clickhouse及其他OLAP产品等基本原理，并有生产化调优等相关实践经验。
5、熟悉数据仓库模型设计，并有丰富的sql使用经验，有数据湖经验优先。
6、熟悉hadoop/yarn/hive等大数据组件。
7、严谨的逻辑思维能力，高水平的沟通能力，有快速学习能力和丰富的问题解决能力，具备高度个人驱动力和执行力，同时具备良好的团队合作精神。
8、对ES、图数据库等生产使用经验者优先									
									
									
									
									
									
									
									
									
岗位职责：
1.熟悉业务流程平台架构和配置，具有与其他系统和第三方平台接口开发和设计能力；
2.负责大数据部门核心系统设计和开发工作；
3.负责系统分析与设计，并负责完成核心代码；
4.根据开发规范与流程独立完成模块的设计、编码、测试以及相关文档。
职位要求：
1.全日制一类本科以上学历，计算机相关专业；
2.JAVA基础扎实，精通IO、多线程、集合等基础框架，精通分布式、缓存、消息、搜索等机制；
3.精通Hadoop，Mapreduce，Spark，Hive，Kafka，Redis等通用框架和组件的相关开发和使用。
4.具有较强数据结构，算法设计与开发能力，对PB级大数据处理有经验的优先，对有高并发系统开发设计经验的优先。
5.精通apache,nginx,Tomcat等应用服务器的使用，熟悉linux常用命令，可部署系统与分析性能；
6.精通面向对象设计方法和设计模式，逻辑能力佳。
7.具有很强的编码功底，有过业务设计经验，能解决疑难技术问题；
8.有过互联网金融类或电商类平台开发经验的优先。									
									
									
									
									
									
									
									
									
职位介绍：岗位侧重于工具平台开发。
1、负责公司数据中台的统一调度平台、实时数仓平台、离线数仓平台、资产管理平台等平台建设，为海量数据和业务系统提供可靠的业务能力支撑。
2、参与业务方大数据领域的需求讨论，给定解决方案，并指导业务方使用数据中台各产品服务，帮助业务方一起解决存储、计算、性能等问题。
3、深入理解系统技术原理和架构，持续进行性能优化和架构迭代，不断提高系统的可用性、可扩展性；
4、深入理解系统使用场景，为业务方提供技术和服务支撑；
5、参与大数据平台的需求分析，撰写技术文档、业务接入文档。
岗位要求：
1、全日制工科、计算机、统计或其它相关专业本科及以上学历，8年以上开发经验，5年以上大数据相关研发和运维经验；
2、熟悉Java/Scala/C++，熟悉至少一门脚本语言（shell、python等）；
3、熟悉Hadoop生态、Spark生态、Flink生态优先，具有二次开发经验优先；
4、有大规模资源调度及系统融合架构开发经验和落地经验；
5、具备优秀的学习能力和表达能力，执行力、沟通能力以及团队协作能力。									
									
									
									
									
									
									
									
									
岗位职责
1. 负责大数据相关平台研发、架构设计
2. 负责数据开发、数据质量、监控告警能力建设
3. 负责百万级别批次离线作业的调度能力建设，满足国际化多场景下任务执行和需求迭代
任职资格
1. 扎实的JAVA编程基础，具备良好的编程习惯，较强独立解决问题的能力，掌握Spring、Spring boot、mybatis开发框架；
2. 有大数据组件使用经验，包括但不限于HDFS/Hive/Spark/Yarn/Kafka/Flink等
3. 有容器Docker/K8S使用经验优先，熟悉Airflow、DolphinScheduler优先
4. 熟悉jvm内存管理、GC算法，熟悉JVM参数调优，熟悉java多线程；
5.  热爱大数据技术，能结合各种技术的优势进行适当的裁剪、方案比选，有较强的trouble-shooting能力，责任心强									
									
									
									
									
									
									
									
									
工作职责：
1. 牵头实时计算框架建设，基于离线/实时计算技术实现金融业务数据计算和应用的最佳实践；
2. 负责Flink SQL查询优化、运行时优化、问题诊断等；
3. 负责开源流计算引擎Flink的调度优化、执行优化，支撑高吞吐、大状态作业稳定运行；
4. 深入理解业务场景，与业务部门合作，推动实时计算在公司落地；
5. 研究最新的数据开发理论和实践，并在团队中实验和落地。
岗位要求：
1. 全日制本科及以上学历，计算机、软件工程等相关专业；
2. 5年以上大数据开发经验、有3年以上Flink任务开发经验。
3. 有超PB级别大数据处理实战经验，熟悉整个大数据的完整处理流程，优秀的问题解决能力
4. 精通Java/Scala语言,熟练掌握主流的Java框架，了解JVM的基本实现原理，有大型后台系统开发经验优先；
5. 精通Kafka、Elasticsearch、Hbase、Kudu等大数据组件；
6. 深入了解Flink原理，熟练使用Flink基本算子，State、多流join、FlinkSql，能够自主开发connector及udf，有复杂场景应用经验者优先；
7. 熟悉Hadoop生态技术，熟练使用hive， spark；熟悉维度建模与数据分层架构，能够独立设计高效易用的数据仓库；
8. 扎实的计算机基础和算法数据结构功底，对技术有热情，愿意不断尝试新技术和业务挑战。									
									
									
									
									
									
									
									
									
工作职责：
1、统筹和规划数据管理类相关工具和系统。
2、负责研究与落地和数据开发相关的工具、平台，提高团队数据开发的效率和能力；
3、探索数据、分析业务领域内的痛点，并与业务沟通，提出相应的解决方案。
任职资格：
1、统招全日制本科以上学历, 计算机专业优先，5年以上大数据开发工作经验。
2、具有丰富的数据类项目开发交付经验，主导项目整体架构设计和管理过程的工作。
3、具备熟练Java开发经验，熟悉微服务框架、中间件、分布式技术等。
4、熟悉Flink、Spark、HBase、Clickhouse及其他OLAP产品等基本原理，并有生产化调优等相关实践经验。
5、熟悉数据仓库模型设计，并有丰富的sql使用经验，有数据湖经验优先。
6、熟悉hadoop/yarn/hive等大数据组件。
7、严谨的逻辑思维能力，高水平的沟通能力，有快速学习能力和丰富的问题解决能力，具备高度个人驱动力和执行力，同时具备良好的团队合作精神。
8、对ES、图数据库等生产使用经验者优先。									
									
									
									
									
									
									
									
									
大数据平台基础架构（计算方向）
职位职责：
1.支撑B站的ETL/Adhoc/BI查询
2.负责Spark SQL、Presto、Hive, Calcite为代表的开源大数据计算引擎的内核优化,对社区有贡献者加分
3.熟悉SQL引擎的优化原理，谓词下推，向量化执行、列式存储，语法转换等
5.良好的Java/Scala编程基础；
6.具备大规模系统的故障诊断与性能优化能力
7.具有较强的项目推动能力，能推动技术项目在业务侧的落地
8.具备一定的业务理解与业务架构能力，能为业务的架构提供方案或建议
职位要求：
1.熟悉SparkSQL、Presto、Hive, Calcite等主流大数据系统原理及源码
2.参与过大型复杂分布式系统的设计、架构者优先
3.具备扎实的Java/Scala语言编程基础，具备良好的编程习惯，较强独立解决问题的能力									
									
									
									
									
									
									
									
									
小红书
岗位名称：数仓研发专家/TL
上海、北京
工作职责
-负责小红书离线数据仓库的设计与开发
-负责带领团队落地数据价值
-负责指导junior同学
职位要求
-5年及以上互联网数据仓库建设经验
-能够独立负责复杂业务模块数仓工作
-善于发现业务中的数据机会，协调相关资源推动数据价值落地
-熟悉数据仓库建设方法论，熟悉大型数据仓库架构和模型设计，精通ETL开发
-精通SQL开发及性能调优，熟悉基于Hadoop，Hive，Spark等分布式计算平台的数据研发
-熟悉数据仓库领域知识和管理技能，包括但不限于元数据管理、数据质量、性能调优等
-熟悉Flink及Scala/Java者优先
-有团队管理和带人经验者优先
-良好的沟通与表达能力和强烈的自我驱动力
福利
房补，福利年假，期权激励									
									
									
									
									
									
									
									
									
工作职责：
1. 负责七猫大数据系统架构设计和规划，设计技术方案、评估资源、推进方案落地；
2. 负责七猫免费小说推荐系统架构设计和规划，设计技术方案、推进方案落地、评估效果；
3. 重难点技术问题攻关解决，能保障PB级系统的稳定运行；
4. 集群公共组件层面问题解决和优化，如参数调优、故障解决、资源利用率提升；
5. 前瞻性技术方案调研和DEMO实现，为即将开发的新功能做好技术储备；
6. 参与团队伙伴的技术带教、培训工作，提升团队整体技术能力。
任职要求：
1. 本科及以上学历，必备5年以上大数据离线和实时分析开发经验，自身技术强悍；
2. 具备推荐系统实践经验，能够指导推荐系统落地，并带领团队不断取得突破和进步；
3. 具备良好的大数据系统的架构能力，从系统底层到上层应用，能够整体把握；
4. 精通大数据集群组件参数调优、错误定位，出现问题时能够快速排查并解决；
5. 有数据挖掘、NLP经验者优先；有一线互联网公司相关项目经验者优先；
6. 有较强的沟通表达能力，善于学习，能迅速理解产品需求，关注用户体验；
7. 有较强的责任心和事业心，有严密的逻辑思维，有追求卓越的精神，能够自我驱动。									
									
									
									
									
									
									
									
									
1、建设本地生活PB级数据仓库，并基于大数据对业务提供深入有效的支持；
2、参与到本地生活流量/用户数据模型开发与优化；
3、参与本地生活数仓横向治理，提升数据模型规范性、准确性、易用性、灵活性，降低计算存储成本消耗；
4、参与流批一体、数据湖、隐私计算等技术等探索和落地应用；
5、支持建设线上数据产品数据研发及数据维护， 如流量系统、圈选系统等。
职位描述
1、有数据仓库需求调研和需求分析经验，能根据业务需求设计数据仓库模型，并对数据仓库数据模型进行管理，保证数据质量，3年以上数据仓库开发实施经验；
2、精通sql开发，有较丰富的Hive sql性能调优经验优先，能开发hive udf者优先；
3、至少能使用Java、Shell、Python、Perl等脚本语言之一；
4、计算机等相关专业，两年以上HBase、MapReduce生产环境工作经验；
5、有Hadoop/Storm/Spark/Hive等系统的开发经验者优先；
6、高度的责任心、良好的团队协作精神，沟通协调能力，良好的分析能力。									
									
									
									
									
									
									
									
									
工作职责:
1、负责搭建永辉超市新零售数据中台，推动永辉新零售业务的快速发展;
2、负责云创大数据平台的架构设计、搭建;
3、负责云创数据仓库（离线、实时）的架构设计、数据模型设计及实施落地;
任职资格:
1、从事数据仓库领域至少5年以上工作经验，精通数据仓库模型架构设计与ETL开发经验，掌握维度建模设计方法，具备海量数据处理经验;
2、精通掌握分布式计算框架Flink、HDFS、Mapreduce、Spark、Hive等其中一项;
3、熟练掌握Python、Shell等编程语言的其中一项;
4、掌握Kylin, Druid, Clickhouse中至少一种OLAP计算引擎
5、熟练掌握Azkaban、Airflow、Datax、Sqoop等开源ETL调度、同步工具;
6、对于数据管理，数据治理，元数据应用有实际应用经验
7、有实际的企业级数据仓库优化经验及较强的Trouble Shooting能力优先;
8、能够快速融入团队，具备良好的语言沟通能力与表达能力;
9、具备良好的自驱力，对技术有追求和激情，研究前沿技术;									
									
									
									
									
									
									
									
									
职位描述
- 负责离线和实时数据的采集、清洗和加载
- 负责用户领域领域数据流的数据处理、查询统计和分析预测等在线计算
- 负责数据模型和指标建设、BI报表开发
职位要求
-计算机本科及以上学历；
-熟悉Hadoop/Spark/Flink/Presto/Hive/Kafka/Flume等大数据技术框架及其生态的使用经验；
-扎实的开发能力，精通Python/Java/Scala中的至少一种，具备一些算法能力尤佳；
-业务理解力强，对数据敏感，有互联网行业数据产品分析经验者优先；
-具有良好的沟通能力和团队合作精神，优秀的分析问题和解决问题的能力，对技术有热情。									
									
									
									
									
									
									
									
									
工作职责：
1.负责数据仓库研发，提供通用、稳定、丰富、高效的公共数据能力
2.负责数据实时标准制定、数据质量监控，保障公数据产出的稳定性
3.负责构建元数据资产，搭建数据治理体系，包括效率、质量、成本、安全等领域
任职要求
1.本科及以上学历，3年以上数据研发经验；
2.熟悉互联网数据全生命周期处理流程，有参与过2个以上的数据治理项目经验
3.有较为丰富的数据仓库研发经验，熟悉数据仓库、数据体系和数据价值的建设及优化；
4.掌握数据管理治理的相关理论，熟悉数据治理、数据标准、企业级数据建模、主数据、元数据管理等方法论；
5.熟悉大数据架构，具备实时或离线数据研发能力，熟悉Hive，Kafka，Spark，Storm，Hbase，Flink等相关技术并有相关开发经验；
6.有数据血缘、图数据库、图计算等相关经验优先									
									
									
									
									
									
									
									
									
计算机本科及以上学历；
-熟悉Hadoop/Spark/Flink/Presto/Hive/Kafka/Flume等大数据技术框架及其生态的使用经验；
-扎实的开发能力，精通Python/Java/Scala中的至少一种，具备一些算法能力尤佳；
-业务理解力强，对数据敏感，有互联网行业数据产品分析经验者，整车研发/制造/安全数据应用开发经验者优先；
-具有良好的沟通能力和团队合作精神，优秀的分析问题和解决问题的能力，对技术有热情。
工作地点：上海									
									
									
									
									
									
									
									
									
负责公司自研数据平台和数据中台的建设，支持全公司各业务使用
负责用户、工业化、整车研发等业务数据算法产品研发
同时精通大数据技术和Java后端技术									
									
									
									
									
									
									
									
									
1 参与本地生活数据仓库的架构设计与研发，建设PB级的数据集市和数据管理，实现高质量数据的互通与共享
2 参与数据产品与应用的数据研发，发掘数据商业价值，与产品技术团队一起打造**体验的数据产品
3 参与数据化运营，构建丰富多样的BI应用，助力业务产品不断优化
4 参与数据对外开放的建设工作，帮助ISV服务商更好的服务每个线下商户
职位要求：
1 从事数据仓库领域2年以上，熟悉仓库模型设计与ETL开发经验，有O2O领域数据建设经验优先
2 掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验,灵活运用SQL实现海量数据ETL加工处理
3 熟悉JAVA语言，有分布式数据存储与计算应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验，重点考察Hdfs、Mapreduce、Hive、Hbase、Spark
4 熟悉数据仓库领域知识和技能者优先，包括但不局限于：数据集市设计、元数据管理、数据质量、主数据管理
5 掌握实时流计算技术，有storm开发经验者优先
6 熟悉Linux系统常规shell处理命令，灵活运用shell做的文本处理和系统操作
7 良好的语言沟通与表达能力、较强的自我驱动能力									
									
									
									
									
									
									
									
									
Spark大数据Flink
岗位职责
1.参与公司离线/实时数仓建设
2.参与算法特征，样本，指标等数据开发
岗位要求
1.从事离线或实时开发至少三年以上熟悉数仓建模
2.对数据治理，数量质量，数据应用有深入了解
3.熟悉spark，flink，hbase，clickhouse，hudi等大数据组件中至少一种
4.具有电商行业经验或互联网行业经验优先，较好的表达沟通能力和上进心									
									
									
									
									
									
									
									
									
FlinkHiveScala数仓建设经验
职位描述
- 负责离线和实时数据的采集、清洗和加载
- 负责用户领域领域数据流的数据处理、查询统计和分析预测等在线计算
- 负责数据模型和指标建设、BI报表开发
职位要求
-计算机本科及以上学历；
-熟悉Hadoop/Spark/Flink/Presto/Hive/Kafka/Flume等大数据技术框架及其生态的使用经验；-扎实的开发能力，精通Python/Java/Scala中的至少一种，具备一些算法能力尤佳；
-业务理解力强，对数据敏感，有互联网行业数据产品分析经验者优先；-具有良好的沟通能力和团队合作精神，优秀的分析问题和解决问题的能力，对技术有热情。									
									
									
									
									
									
									
									
									
大数据平台架构经验
岗位职责：
1、 配合大数据负责人搭建大数据平台及应用的整体架构的规划和设计,架构的选型与方案评估；制定数据架构规范，指导落地；
2、 负责数据基础架构和数据处理体系的升级和优化，不断提升系统的稳定性和效率，为公司的业务提供大数据底层平台的支持和保证；
3、 负责数据资产管理体系建设，制定数据资产管理制度与流程，规划数据治理体系建设；
4、 研究未来数据模型和计算框架的创新与落地，包括但不限于以下领域：大规模数据实时化、研发模式敏捷化、数据计算框架轻量化、数据模型组织方式业务化等方面,参与制定并实践团队的技术发展路线；
5、 建立良好的公司内外的业界技术影响力；参与培养未来数据人才；有效辅导团队，提升数据研发能力。
岗位要求：
1.计算机相关专业本科以上学历；
2.5年以上大数据行业相关经验，4年以上大数据架构设计经验；
3.熟悉Hadoop、Spark、Flink、Kafka、HDFS、Hive、ES、Druid等主流大数据系统原理及源码，熟悉MySQL、PostgreSQL、NoSQL等数据库中至少一种数据中心建设方案，可以进行产品的独立部署、高可用架构和性能优化，熟悉开源社区解决方案；
4.对数据采集、数据开发、数据分析、数据建模、算法等有深刻认识和实战经验，具备大规模系统的故障诊断与性能优化能力；
5.在大数据架构、产品、技术等方面有深入思考和中长期的产品和技术视野，对技术架构演进有清晰、成熟的思路；
6.负责过多条大数据业务线或整个产品线的业务架构工作，组织过中等以上规模项目者优先，有企业级应用大数据行业经验优先；
7.熟悉分布式应用系统的相关框架及技术，熟悉Spring Cloud，Dubbo等微服务框架，有容器/微服务、中间件、开源大数据、基础云服务等技术积累和实战经验；
8.熟悉常见的大数据、云计算、人工智能等技术和知识，有互联网或物流大数据平台建设等技术背景者优先；
9.具备良好的需求分析能力、业务和技术方案策划和设计能力，有较强的逻辑思维能力，思路清晰，善于分析、归纳、解决问题，能够独立或带队进行项目开发；									
									
									
									
									
									
									
									
									
大数据KafkaJava分布式技术多线程消息队列后端开发
团队介绍：
eBay大数据实时计算团队，以打造高可用及可扩展的企业级实时计算平台为目标，为eBay支付、搜索、广告等领域提供基于Kafka，Flink以及消息队列的实时计算解决方案。
工作内容：
•	设计及开发基于Kafka的大数据云原生实时计算平台和消息队列服务，包括Kafka集群和消息队列的生命周期管理和运维，监控告警，性能调优等，与开源社区紧密迭代，解决实时计算领域的用户痛点。
岗位要求：
•	精通Java和SQL开发，有一定的系统设计能力。
•	三年以上工作经验，有大数据和分布式系统开发背景的优先。
•	追求技术卓越，积极主动、有合作精神，善于沟通能，能够跨团队合作。
•	有Kafka/Flink/Spark/Pulsar/RabbitMQ/RocketMQ等开发背景的优先。
•	大数据开源项目committer/PMC优先。
•	有基本的英文听说读写能力。									
									
									
									
									
									
									
									
									
SQLSparkJavaETL开发经验大数据开发经验数仓建设经验
1、建设本地生活PB级数据仓库，并基于大数据对业务提供深入有效的支持。
2、负责饿了么数据仓库的开发与优化。
3、能基于一致性、及时性、准确性的要求不断提高仓库质量。
4、协助本地生活大数据平台的建设， 包括大数据计算系统、 实时数据系统、分布式调度系统、高可用数据同步系统等。
5、支持建设线上数据产品数据研发及数据维护， 如商家系统、供应商系统、流量系统等。
职位描述
1、有数据仓库需求调研和需求分析经验，能根据业务需求设计数据仓库模型，并对数据仓库数据模型进行管理，保证数据质量，3年以上数据仓库开发实施经验
2、精通sql开发，有较丰富的Hive sql性能调优经验优先，能开发hive udf者优先；
3、至少能使用Java、Shell、Python、Perl等脚本语言之一；
4、计算机等相关专业，两年以上HBase、MapReduce生产环境工作经验
5、有Hadoop/Storm/Spark/Hive等系统的开发经验者优先
6、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。									
									
									
									
									
									
									
									
									
JavaFlinkSpark大数据开发经验实时计算k8s
工作职责
1、打造业界一流的实时数据平台，快速高效支撑实时数据流业务升级和改造
2、基于flink实时数据平台的开发、设计和架构，提供高可用、可维护、易用性的一站式实时数据开发平台
3、规范和管理flink计算资源，降低运维成本，提高计算资源的利用率
任职资格
1、本科及以上学历，3年以上数据平台研发经验，有实时数据平台开发经验的优先；
2、精通java后端开发，对微服务系统设计和架构有一定的理解
3、熟悉大数据生态，包括但不限于flink、spark、hadoop等
4、对k8s容器技术有一定的了解
5、具备快速的学习能力，跨团队的沟通能力，有较强的逻辑思维能力和解决问题的能力									
									
									
									
									
									
									
									
									
大数据平台架构经验大数据处理经验数仓建设经验
岗位职责：
1、负责规划和维护支撑PB级数据量的自动驾驶大数据闭环管理平台，支持平台落地，优化存储和计算性能；
2、参与建设车路协同的离线&实时数据pipeline，赋能数据大屏、AI训练与仿真平台等；
3、参与传感器、毫米波雷达、摄像头等采集数据治理、数据加工处理等工作；
4、负责自动驾驶大数据闭环管理平台相关的基础设施运维保障；
任职资格：
1、5年以上大数据平台相关研发或运维经验，2年以上大数据架构实战经验，有自动驾驶数据平台管理经验优先，有IOT物联网数据平台经验优先
2、精通大数据生态相关技术，具备使用、维护、调优的能力，包括但不限于Hadoop、HBase、Hive、Flink、Spark、ClickHouse、HDFS、Yarn等，对离线/流式计算、时序数据处理、存储引擎、资源调度等一项或多项有深入理解及实战经验；
3、有能力搭建维护并优化分布式文件存储系统、对象存储系统；有参与搭建数据湖，数据仓库经验；
4、掌握java/scala，以及至少一门脚本语言（shell、python等）；
5、熟悉数据标准管理、元数据管理，有非结构化数据治理相关项目的工作；
6、有Hadoop生态相关技术源码研究、二次开发经验优先；									
									
									
									
									
									
									
									
									
JavaPythonSparkStormHadoopFlink
部门介绍：
数据科学与平台部是美团大数据领域平台化中心团队，在公司零售+科技战略的指导下，以持续建设公司核心数据能力，创造业务价值，赋能业务增长，以科技创新驱动行业的数字化发展为己任。
作为公司大数据领域的核心驱动团队，无论是B端商业数字化、C端服务智能化、还是平台高效履约以及美团内部运营精细化等，都是我们实战的场景。
在这里，能够接触到行业内部领先的数据应用和数据产品内容，实践到大数据基础架构工业界领先技术，有完善的互联网学习生态圈，技术大牛零距离全栈助力成长，还有机会与业界一流的工程师团队同行，挑战行业前沿技术难题。
期望保有好奇，保持初心的伙伴，同我们一起驱动技术创新，创造价值落地！
岗位职责：
负责广告平台的（实时、离线、流批一体）数据仓库的建设，数据方案设计，模型开发，指标体系的开发和数据治理；
理解到店广告营销、投放、引擎、算法等业务逻辑，与广告产品、产品运营、BA等合作支持广告业务数据迭代；
岗位基本要求：
计算机或者相关专业大学本科及以上学历；
精通SQL/Java/python等至少一种开发语言；
熟悉hadoop/hive/spark/storm/flink等原理；
熟悉常见数据仓库设计、治理原理，有海量数据的数仓设计和开发经验；
有较好的学习能力，沟通表达，思路清晰，积极主动，聪明，韧性，有进取心；
具备以下优先：
有极强的学习能力，有负责过大型跨团队合作项目者优先；
有大型广告系统海量数据开发经验者优先；
参与过财务结算等复杂业务核心系统建设者优先；
岗位亮点：
有探索流批一体等前沿的海量数据开发框架的机会；
与优秀的数据平台团队深度合作建设数据体系的机会；
与优秀的广告算法、工程、产品等团队合作建设广告系统的机会；									
									
									
									
									
									
									
									
									
SQLSparkKafkaHDFSPrestoAzkaban
工作职责
负责数据仓库及数据应用的系统分析、模型设计等开发建设工作
负责与用户沟通澄清需求，需求项目的设计、开发测试及生产验证计划等制定并实施
负责推动执行数据规范及数据治理工作，落实架构要求
任职资格
本科及以上学历，计算机相关专业，5年以上数据开发工作经验
熟练使用Hive、HDFS、Presto、ClickHouse、Kafka、Spark、Azkaban、ES、Hbase等大数据开源组件并在实际项目中基于相关组件的开发经验
熟练使用Oracle、MySQL、PG、TiDB等关系型数据库，并在实际项目中有相关的开发经验
熟练使用Java、SQL等开发语言
熟练数仓体系结构及数仓模型设计方法，有数据仓库模型设计经验
熟悉使用报表开发共计及数据展现工具，有实际的数据应用先关开发经验
具备丰富的数据需求分析和数据调研验证能力，具有金融行业经验优先									
									
									
									
									
									
									
									
									
数据架构数据仓库数据开发数据模型大数据仓库
作为数据技术与产品研发团队的一员，在拼多多，你每天将：
1.在社交电商领域排名第一的新兴独角兽公司中切身感受和个人同时高速成长的感觉；
2.承担年付费用户超8亿的业务所带来的巨大技术挑战；
3.用数据提高效率和改变业务运营方式，规划数据技术发展方向，带动团队技术氛围；
4.有机会使用数据来影响每天有数亿人使用的产品的产品决策，深入发掘数据带来业务价值；
5.与来自Google、微软、雅虎、BAT的大神共事，数据驱动业务，用数据技术改变互联网电商行业！
同时，我们也希望您能：
1.参与建设拼多多统一的数据体系，持续集成相关工具产品，以及搭建大数据业务统一计算层等相关工作；
2.参与拼多多数据仓库的架构设计和研发，挖掘数据价值，建设与管理X PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
3.助力数据化运营业务，构建丰富多样的BI应用；
4.对数据采集、数据融合、数据质量、数据应用链路有深入理解，并能协助业务数据集市建设，搭建业务领域模型；
岗位要求（性别、年龄、学历、技能、经验、素质等方面）：
1.数学、计算机、统计学等相关专业本科以上学历，5年以上相关工作经历；
2.从事数据仓库领域至少5年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验；
3.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase；
4.有实时ETL研发经验，对分布式实时大数据处理系统有深入理解，包括但不限于Spark streaming、Flink、Storm...；
5.熟悉数据仓库领域知识和技能者优先，对数据质量管理有独到的见解；
6.具有电商行业经验，有业务sense，能够通过梳理设计业务模型发现业务问题，并驱动业务目标实现；
加分项：
1.对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先，并有落地的项目；
2.对Elasticsearch、Hbase、Druid、Kylin有深入理解并成功应用的大型项目；									
									
									
									
									
									
									
									
									
SQLHIVESparkZookeeperHDFSFlinkPrestoOlap
职位描述
计算机本科及以上学历；-熟悉Hadoop/Spark/Flink/Presto/Hive/Kafka/Flume等大数据技术框架及其生态的使用经验；-扎实的开发能力，精通Python/Java/Scala中的至少一种，具备一些算法能力尤佳；-业务理解力强，对数据敏感，有互联网行业数据产品分析经验者优先；-具有良好的沟通能力和团队合作精神，优秀的分析问题和解决问题的能力，对技术有热情。
职位要求
计算机本科及以上学历；-熟悉Hadoop/Spark/Flink/Presto/Hive/Kafka/Flume等大数据技术框架及其生态的使用经验；-扎实的开发能力，精通Python/Java/Scala中的至少一种，具备一些算法能力尤佳；-业务理解力强，对数据敏感，有互联网行业数据产品分析经验者优先；-具有良好的沟通能力和团队合作精神，优秀的分析问题和解决问题的能力，对技术有热情。									
									
									
									
									
									
									
									
									
Java系统架构Hadoop
-	职责描述：
-	负责大数据平台技术框架的选型与技术难点攻关
-	负责规划数据挖掘的整体流程，负责大数据开发团队业务需求开发
-	与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化
-      负责新技术的调研，并能在团队内进行推广应用
-      负责公司大数据底层框架的整体架构设计，结合公司实际业务情况进行技术选型及大数据战略规划；
-	
-	任职要求：
-	计算机、数学相关专业，本科以上学历；5年以上开发经验，其中3年以上大数据架构或相关工作经验；有大型零售大数据、电商平台系统设计和架构经验hadoop平台开发经验
-	熟悉Hadoop生态圈其他系统，包括Hive，Pig，HBase，Spark，Kafka，Oozie，Sqoop，Flume，ZooKeeper, Strom,FLink,并了解其原理
-	具备大型复杂Hadoop数据平台的建设实施经验
-	精通Java及Python,有架构设计能力和良好的编码习惯
-	能够承受一定工作压力，有团队合作精神									
									
									
									
									
									
									
									
									
Java
职位描述：
1：培养与管理公司大数据团队，包括大数据基础建设和数据分析挖掘团队；
2：负责公司大数据平台、数据中台、BI系统的规划、建设与交付，技术核心攻坚；
3：负责建立和维护大数据平台技术标准规范、采集规范、数仓规范，建设数据采集评估标准；
职位要求：
1：本科及以上学历，6年及以上大数据、BI开发经验，3年以上团队管理经验，对数据分析领域有较强理解，主导设计过数据分析、数据挖掘相关产品，深入了解主流大数据技术、产品的现状和发展趋势；
2：较深入地了解基于Hadoop生态的大数据系统及传统数据仓库技术，例如hive、hbase、storm，kafka,、spark、flink等等，具备良好的大数据平台架构设计能力；
3：对数据敏感，条理清晰，具有较强的分析问题和解决问题的能力；
4：热爱编程，深刻理解计算机原理，有良好的数据结构和算法基础，扎实的编程能力；
5：有较强的学习能力，有强烈的求知欲、好奇心和进取心，能及时关注和学习业界最新技术；
6：积极乐观，责任心强，工作认真细致，有良好的团队沟通和协作能力。									
									
									
									
									
									
									
									
									
职位描述
微信扫码分享 举报
大数据开发经验数仓建设经验
工作职责：
1、 负责大数据清洗、存储、处理、分析等场景的开发工作;
2、 参与大数据平台相关的功能接口、数据接口的设计与实现;
3、 参与基于azkaban的数据调度任务的配置;
4、 参与基于Hadoop/Spark生态的大数据处理平台的开发;
岗位要求：
1、 本科或以上学历，计算机相关专业;
2、 4年以上工作经验，2年以上大数据相关经验;
3、 熟悉 Hadoop、Spark， Hive， Kafka， ES等大数据相关技术和产品;
4、 熟悉至少一种常用数据库语言（Oracle/MySQL/PG等）;
5、 熟悉RESTFul API，使用过常用的Azkaban/kettle 等工具;
6、 深刻理解大数据处理等相关技术和实现方法，有架构和设计实践经验优先;
7、 对数据敏感，有数据分析、数据挖掘经验者优先;
8、 有大型数据仓库实施、大数据平台数据开发经验者优先。									
									
									
									
									
									
									
									
									
职位描述
微信扫码分享 举报
JavaPythonSQL大数据开发经验数仓建设经验ETL开发经验
职位描述：
● 负责企业信用数据的全生命周期管理，包括但不限于数据的接入、融合、分析等工作
● 负责企业信用数据资产管理平台规划设计和平台化建设
● 负责数据标准、数据质量和元数据的规划管理，并产出数据治理方案
● 与业务团队紧密配合，前瞻性的构建基础数据能力，赋能业务
● 负责线上系统和数据的维护和管理，包括但不限于阿里云
职位要求：
● 精通数据开发和数据建模，对数据敏感且对处理大量数据有强烈兴趣
● 熟练使用 Python/Java，有良好的编程能力和工程实践
● 熟悉大数据生态相关技术，如：Hadoop/Hive/Spark/Flink/Storm/Kylin/Druid/Hbase/Kafka等；
● 具备优秀的需求抽象和架构设计能力
● 良好的沟通及表达能力，注重团队协作，工作细心认真，喜欢探索钻研，有独立思考的能力
● 有大数据研发经验者优先，有数据平台相关产品经验者优先，有 DevOps 经验优先									
									
									
									
									
									
									
									
									
SparkHadoopJava数据平台大数据运维
岗位职责：
1、大数据集群的维护调优与稳定性保障；
2、负责大数据平台技术框架选型与各项技术难点攻关；
任职资格：
1、本科及以上学历，计算机相关专业，2年以上工作经验；
2、精通java和python等语言；
3、精通主流开源的大数据平台的技术架构，熟悉主流大数据组件。包括但不限于Hadoop,hbase,spark,alluxio等；
4、对大数据基础组件有源码和实际生产调优经验更佳；									
									
									
									
									
									
									
									
									
数仓数分
需求：L7-9  薪资可谈
部门介绍
到家研发平台秉承“零售+科技”战略，致力于推动餐饮、零售需求侧和供给侧数字化升级，构建了超大规模的在线交易平台和实时调度系统，保障了百万商家和亿级用户的高效安全交易，实现了对百万骑手所在物理世界全链路的数字化。随着万物到家业务战略推进，我们在需求侧致力于通过大数据与大算力深度融合，建设强大的LBS零售电商系统和平台；同时，在供给侧紧密关注决策智能、因果推断和机器人等诸多新技术的发展和应用，建设行业领先的智能决策平台。
到家研发平台，一方面通过系统和技术体系的迭代升级，帮助业务高质量增长，另一方面，密切关注技术趋势变化，提前进行核心方向布局，积极探索前沿技术领域，为业务未来发展创造新的可能性。加入我们，一起用技术让人们的生活更加简单，更加美好。
岗位职责
1.负责外卖流量数仓的设计和建设，包括但不限于外卖流量数仓的模型设计、数据治理、数据稳定性和相关报表等；
2.负责面向外卖策略和算法数据（推荐搜索、实验分析评估）的诉求，提供高质量、稳定的标签和特征数据，高效支撑策略算法迭代；
3.负责外卖统一标签和画像平台的设计和开发，高效支持外卖营销、广告等多个业务；
4.对标业界前沿技术方向，并推动在业务中落地；
岗位基本要求
1. 计算机或相关专业，计算机基础知识扎实，4年以上数据相关工作经验；
2. 精通数据仓库建模理论、ETL和SQL开发，有实际的数仓建设经验和大数据开发经验（离线和实时）；
3. 熟练使用Flink、Hive、Spark等离线数仓和实时数仓计算框架，并深入知晓原理；
4. 熟练使用Java、Mysql进行数据系统开发，熟练掌握Spring MVC、Spring boot等开发框架，对数据结构有较深刻的理解，有常用的中间件工程实践经验比如消息队列、缓存系统等；
5. 熟练掌握并实践过数据仓库的指标管理、数据治理、数据质量保证等；
6. 优秀的沟通表达能力和团队协作能力，良好的分析问题和解决问题的能力；
7. 优秀的业务理解能力，能够站在业务角度分析问题和解决问题。
具备以下条件优先
1.有互联网大数据量复杂场景的数据仓库实践经验者优先；
2.有团队管理经验者优先；
3.有Clickhouse、Doris等OLAP和Hudi等数据湖系统经验者优先；
4.有海量数据分析和查询优化经验者优先；
5.有标签和画像相关数据系统建设经验者优先;
岗位亮点
1.能够深入外卖业务，参与快速发展的外卖经营、营销、推荐、广告等业务，并有机会通过数据赋能业务取得更好的发展
2.有机会推动和实践数据湖等数据处理技术，并在业务中落地；
3.能够在实践中解决面向海量数据规模、复杂业务场景的数据查询和分析优化；									
									
									
									
									
									
									
									
									
HbaseETL开发经验
岗位职责	
1.建设拼多多统一的数据体系，持续集成相关工具产品，以及搭建大数据业务基础计算层等相关工作；
2.参与拼多多数据仓库的架构设计和研发，挖掘数据价值，建设与管理百PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
3.助力数据化运营业务，构建丰富多样的BI应用。
任职要求	
1.从事数据仓库领域至少2年以上，熟悉数据仓库模型设计与ETL开发经验，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验；
2.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase；
3.熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；
4.有良好的业务及产品感觉，可以站在使用者角度设计技术产品。可以主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力；
5.熟悉各种NoSQL产品，熟悉分布式架构者优先；有图数据库开发经验者优先；
6.对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先。									
									
									
									
									
									
									
									
									
数仓建设经验大数据开发经验
跨团队招聘，请勿多次投递相同的岗位
工作职责:
1、负责数据的ETL设计、开发、优化，保证数据准确与稳定
2、负责构建业务数据分析体系，帮助确定各项业务数据指标
3、负责数据平台相关后端功能系统设计和开发
工作要求:
1、计算机或相关专业本科以上学历，至少3年以上数据开发实际工作经验
2、负责过大型数据平台和数据仓库设计，具有扎实的大数据和数据仓库的理论功底
3、熟悉数据分析建模原理和流程，能够围绕业务特征建模解决业务问题
4、掌握python/go，掌握python/go WEB开发常规模式，熟悉微服务架构
5、熟悉常用机器学习算法，包括但不限于RF、GBDT、XGboost、SVM、ANN等
6、拥有优秀的分析及解决问题的能力，良好的沟通能力，思维逻辑清晰，有强烈的责任心，并能自我驱动成长									
									
									
									
									
									
									
									
									
数据研发工程师-企业效率方向
工作职责：
1、负责企业效率业务下的数据资产建设，提供通用、稳定、高效的公共数据能力；
2、负责企业效率业务下离线和实时的数据需求交付，持续提升数据支持业务的效率；
3、完善数据质量体系，建设常态化数据治理能力，提升数据易用性、可用性；
任职资格
1.	计算机相关专业，本科及以上学历，基础扎实，3年以上数据研发/数仓建设/数据治理相关经验
2.	精通SQL，熟练掌握Java/Python中的一种或多种
3.    有企业信息化（包括但不限于人事、采购、财务等）相关数据研发经验者优先
4.	熟悉主流大数据处理技术（Hive/Kafka/Spark/Flink/ES等）并具备相关开发经验者优先
5.	责任心强，积极主动，有良好的沟通能力和团队合作能力
6.	对数据敏感，具备优秀的逻辑思维，对解决挑战性问题充满热情，善于解决问题和分析问题									
									
									
									
									
									
									
									
									
SparkShellPython大数据开发经验数仓建设经验
工作职责： 1.基于Hadoop数据平台，参与数据开发及各类数据模型建设工作； 2.负责数仓任务开发并对现有数仓进行优化； 3.负责公司端游和手游等游戏项目的数据中心的建设，和数据报表的开发； 4.参与公司其他大数据类研发项目，结合大数据平台探索应用场景并参与实施。 
 职位要求
 1.本科及以上学历，3年及以上数仓开发工作经验； 2.熟悉数仓领域各种理论知识，如元数据管理，数据质量治理等，可以根据实际业务设计数仓模型； 3.对Hive有相对深入的理解及实际优化经验，熟悉Linux常用命令，以及Python、Shell等脚本语言； 4.熟练使用Hadoop生态圈技术，如：Hive、Hbase、MapReduce、Kafka、Flume等； 5.熟悉Kafka、Pulsar、RabbitMQ等至少一种消息中间件，熟悉 Storm、Flink、Spark Streaming等至少一种流式数据处理框架； 6.具备一定的Java开发及调试能力，熟悉可视化工具者优先；  7.具有强烈的责任心和充分的主动性，能够积极主动的推进项目的进展； 8.具有较强的抗压能力和学习能力，能够独立、高效地发现和解决或推动解决各种疑难问题； 9.具有良好的沟通能力和团队合作能力。									
									
									
									
									
									
									
									
									
KafkaSpark大数据开发经验
岗位职责：
1.负责大数据清洗、存储、处理、分析等场景的开发工作
2.参与大数据平台相关的功能接口、数据接口的设计与实现
3.参与基于azkaban的数据调度任务的配置
4.参与基于Hadoop/Spark生态的大数据处理平台的开发
岗位要求：
1.本科或以上学历，计算机相关专业;
2.5年以上工作经验，3年以上大数据相关经验；
3.熟悉Hadoop、Spark, Hive, Kafka, ES等大数据相关技术和产品；
4.熟悉至少一种常用数据库语言(Oracle/MySQL/PG等)；
5.熟悉RESTFul API，使用过常用的Azkaban/kettle 等工具；
6.深刻理解大数据处理等相关技术和实现方法，有架构和设计实践经验优先；
7.对数据敏感，有数据分析、数据挖掘经验者优先；
8.有大型数据仓库实施、大数据平台数据开发经验者优先。									
									
									
									
									
									
									
									
									
Spring/Spring BootMySQL/Redis/MongoDB大数据
岗位职责：
1、负责腾讯云大数据相关产品的研发；
2、负责与客户进行持续需求沟通，通过完善产品功能服务好企业客户。
岗位要求：
1、计算机、通信等相关专业，本科及以上学历，3年以上大型互联网产品或分布式系统开发设计经验；
2、扎实的java技术基础，对linux，分布式系统，高并发等技术经验丰富；
3、对大数据领域相关组件如（spark, airflow,es,fate等）有丰富的使用经验；
4、在企业内部或云，有大数据领域相关组件如（spark, airflow,es,fate等）产品化经验优先；
5、在企业内部或云，有大数据开发平台、数据湖等产品的研发经验优先；
6、有联邦学习或多方安全计算相关领域经验优先									
									
									
									
									
									
									
									
									
SQL
职位描述：
1、参与公司游戏业务数据仓库的构建、调优及技术管理工作；
2、基于数据体系对业务提供深入有效的支持，合理建设指标体系、用户画像、报表体系等，支持产品数分和运营的各类需求；
3、负责与业务团队建立良好的协作关系，并与数据PM紧密合作，致力于推进数据赋能业务，对结果和效果负责；
4、基于一致性、及时性、准确性、安全性的要求，不断提升数据易用性与数据服务质量；
职位要求：
1、掌握数据仓库体系架构、数据建模方法，指标体系方法等，具备数仓模型设计及管理能力，具有0-1建设数据仓库经验优先；
2、善于沟通，对业务敏感，与业务团队紧密合作，理解并合理抽象业务需求，推广及发挥数据价值，具备优秀的技术与业务结合能力；
3、掌握大数据技术栈，包括Hadoop/Hive/spark/OLAP引擎等，精通SQL/ETL开发，熟悉Python/Java等其中一项编程语言；
4、具备丰富的离线数据体系建设及保障经验，提升数据易用性及数据质量；
5、6年以上数据仓库或大数据开发经验，有大数据团队管理经验更佳；									
									
									
									
									
									
									
									
									
SparkJavaHive大数据平台架构经验大数据处理经验
岗位职责：
1、负责企业级数据存储和计算平台的开发和运营
2、负责数据开发和治理平台的开发与运营
3、负责指标中台和自助分析等数据服务系统的开发和运营
4、负责公司层面的数据治理，提高数据质量和时效
5、负责数据平台团队人员管理工作
岗位要求：
1、本科或以上学历，计算机相关专业
2、具有8年以上大数据平台相关开发经验及互联网从业经验
3、精通Java/Scala开发，精通HDFS、Yarn、Spark、Flink、Presto、Clickhouse、Alluxio、Kylin等大数据开源组件原理及使用
4、具备大规模Hadoop集群运营、Hudi/Iceberg湖仓一体等相关经验优先
5、熟悉Kimball维度建模理论和实践
6、具有良好的语言表达能力和协调沟通能力，有较强的压力承受能力									
									
									
									
									
									
									
									
									
JavaScalaSparkKafkaHadoopFlink
职位描述
1、负责面向发行的BI系统后端研发，功能设计、开发实现、以及运营维护；
2、持续改善已有服务，分析系统瓶颈，优化系统薄弱点，提升性能和稳定性；
3、为上下游和最终用户提供标准化服务，保证优质体验。
职位要求
1、熟悉大数据基础架构、业务数仓架构，能够针对业务需求进行合适的技术选型，并持续迭代优化；
2、熟悉大数据生态组件，包括Hadoop、Hive、Spark、Flink、kafka等；
3、精通Python/Go/Java/Scala至少其中一门编程语言；
4、数据仓库建模及数据ETL开发经验者优先；
5、有OLAP开源引擎（clickhouse等）项目经验优先；
6、熟悉aws、k8s，有游戏发行、广告平台、商业化经验者更佳
7、有热情，爱学习，关注大数据前沿技术发展，逻辑思维能力好，有较强解决问题能力；									
									
									
									
									
									
									
									
									
PythonDruidFlinkSparkHIVE
职位描述
1、广告各类在线业务的离线数据加工与在线数据服务开发与维护 2、数据服务接口及产品需求研发迭代，代码review、bug修复及日常服务运维 3、针对海量数据处理和查询需求，设计适应业务变化的合理的多维数据分析系统架构，满足多样性的需求 4、海量日志清洗加工，并抽象出可以多业务复用的数据模型
职位要求
1、计算机相关专业本科以上学历，熟悉Hadoop架构和工作原理，精通MapReduce编程；精通Hive，有HQL优化经验 2、熟悉JAVA，python等多种编程技术，编程能力强，有web服务开发经验，具备独立完成模块开发能力 3、理解基本的设计模式，能将业务需求快速理解成技术需求 4、熟练使用Mysql，熟练使用ElasticSearch、Druid者优先；熟悉其原理者优先 5、善于沟通，工作积极主动，责任心强，具备良好的团队协作能力 6、具备良好的问题分析与解决能力，有较强学习能力和逻辑思维能力  额外加分项:： Github等开源社区贡献者 具备大规模分布式服务设计能力和经验									
									
									
									
									
									
									
									
									
Spark
职位描述:
1、建设运营增长数据能力，提供丰富、稳定的短视频直播社区基础数据，探索更多数据能力的业务价值；
2、建设运营增长数据体系，通过数据+策略+产品的方式，赋能业务，提供全链路、可分析、可复用的数据能力，探索更直观、更具业务指导性的产品建设；
3、建设公司级核心数据资产，与运营增长业务场景深度结合，为目标用户提供能解决业务实际问题的数据方案；
4、参与全站数据治理和管理体系，结合业务+元数据+技术，保障数据质量和产出稳定。
任职要求
1、较为丰富的数据仓库及数据平台架构经验，期望通过对业务的深入理解，进行数据仓库、数据体系和数据价值的建设和优化；
2、有从事分布式数据存储与计算平台应用开发经验，熟悉Hive，Kafka，Spark，Storm，Hbase，Flink 等相关技术并有相关开发经验；
3、有系统化的思维和工程化的能力，有工程化落地的经验是加分项；
4、有应用策略开发经验，对机器学习和AI有一定的了解是加分项。									
									
									
									
									
									
									
									
									
SQL
*资历不限，初级工程师、中级工程师、高级工程师、专家工程师皆有需求
①岗位职责
1.负责零售与仓配业务相关基础数据的建设，包括数据埋点的设置，数据仓库的建立和维护，报表的开发，业务系统的数据开发等；
2.负责保证数据的正确性和丰富性；
3.负责开发实时数据和离线数据，推动全链路的线上化和数字化。
任职要求
1、良好的SQL能力,从事过数据仓库开发和业务分析等相关工作；
2、熟悉互联网公司数据模型、数据标准，具备电商数据集市建设经验和数据治理经验；
3、认真负责，有较强的执行力，书面表达能力，积极而有效的沟通；良好的适应能力。
②岗位职责：
1、负责业务数据和用户行为日志的实时采集、计算、存储、服务，为业务团队提供直接数据决策;
2、采集用户的实时行为，计算实时用户画像数据，为线上业务提供数据支持；
3、负责部门实时计算体系架构建设。
任职要求
1、掌握实时计算技术体系包括数据采集、计算引擎flink、 spark streaming等,对实时计算所涉及的事务、容错、可靠性有深入理解 并有实际项目经验；
2、熟悉 hadoop 生态包括 hdfs/mapreduce/hive/hbase,熟悉 kafka 等实时开源工具并有项目经验；
3、熟悉 sql数据库等,熟悉 redis 内存数据库,熟悉 linux 系统;
4、熟练使用 sql语言,熟悉 java等编程语言；
5、有良好的沟通能力和自我驱动动力,具备出色的规划、执行力,强烈的责任感,以及优秀的学习能力。
③岗位职责：
1.负责大数据开发平台的设计与研发，包括开发IDE、任务调度、监控运维、元数据管理、adhoc查询等。
2.完善平台功能，优化用户使用体验。
3.负责线上问题的排查和解决，持续优化和提高系统能力。
任职要求
1.计算机基础知识扎实，包括操作系统、计算机网络、数据结构、基础算法、数据库等。
2.编程能力扎实，熟练使用Java、SQL语言编程，熟练掌握SpringBoot、Mybatis等框架，有一定的DEBUG及性能优化能力。
3.热衷于并擅长troubleshooting 和 performance tuning，喜好专治各种性能和异常的疑难杂症，并乐于做技术剖析、总结沉淀。
4.在大数据开发平台领域有研发经验者优先，熟悉大数据生态者优先。
5.执行力强，对工作有责任心，具备良好的沟通以及协调能力。
④岗位职责：
    针对数据仓库、搜索、推荐、机器学习等场景，优化EB级大数据存储系统的性能和成本，提供跨地域可横向扩展的能力，构建元数据系统，提供业务自动化迁移能力。
1. 优化大数据存储系统(HDFS)的效能，使用多层次存储、EC编码等手段降低运营成本，利用操作系统层缓存、内存、NVME等设备优化存储系统的读写性能，提高上层应用的效率；
2. 开发大数据存储系统(HDFS)的跨地域方案，利用有限的带宽和资源实现对用户透明、一致性的使用体验，保障存储系统多地域的可横向扩展性；
3. 开发描述大数据存储的元数据系统，建立全局统一的目录树结构，简化上层应用与底层存储的交互，实现可横向扩展的元数据系统，并提供业务透明的自动化迁移能力，降低运维成本
任职要求
1. 扎实的计算机理论和编程基础，熟悉常见的分布式理论和系统，熟悉JVM和Linux
2. 对Hadoop生态组件熟悉，在大数据计算和存储相关领域有相关研发经验并有产品落地
3. 具备科学清晰的问题解决思路，良好的沟通能力以及团队协调能力，崇尚数据价值和数据决策，富有责任心									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
Java电商/零售行业数据相关经验物流数据应用flink
岗位职责：
1.负责配送实时/离线数据应用建设的规划、设计及落地，为数据产品团队、策略团队以及业务团队提供高效的实时/离线数据支持；
2.负责实时/离线数据计算和数据服务的性能优化、稳定性建设。
3.负责数据化运营创新性产品的驱动建设
专业要求：
1、扎实的大数据和分布式系统建设经验，具备O2O、物流领域的业务数仓建设与数据资产架构治理经验；
2、具有高性能、高稳定百万级数据服务建设的相关领域经验；
3、具备B端数据化运营产品应用相关架构及实施经验									
									
									
									
									
									
									
									
									
后端工程师
岗位职责
1、负责腾讯云实时计算平台Oceanus的开发与设计；
2、负责腾讯云实时计算平台Flink内核生态的开发与设计。
岗位要求
1、本科及以上学历，计算机相关专业，3年以上相关工作经验;
2、熟悉 Linux 开发环境，精通Java/Golang/C++一种或多种编程语言 ；
3、扎实的数据结构，算法和编程功底，有良好的编程习惯和风格;
4、有SQL引擎优化开发，比如Apache Calcite/SparkSQL/Beam等项目经验者优先；
5、熟悉TCP/IP协议栈，具有TCP/UDP网络编程相关经验;
6、熟悉Flink计算引擎底层原理、有Flink内核或者Connector开发经验者优先；
7、在Flink社区有代码提交者或者Committer者优先 ；
8、熟悉K8S和Docker等容器技术者优先;
9、优秀的分析问题、解决问题能力和团队合作意识、有良好的责任心、善于沟通、工作上能自主驱动、用于接受挑战、富有创新精神;
10、通过腾讯云技术认证或同等资格认证的优先录取 通过腾讯云从业资格证或同等资格认证的优先录取。									
									
									
									
									
									
									
									
									
JavaSparkHbase
大数据平台开发
岗位描述：
1、负责自动驾驶大数据平台的方案设计，构建大数据闭环，满足算法开发验证和仿真测试；
2、开发数据采集、分析、可视化、标注平台等工具链，加速算法和功能开发；
3、负责解决攻克数据系统平台的技术难题。
任职要求：
1、计算机或相关专业，本科及硕士以上学历；
2、具备扎实的数据结构及算法功底，掌握Java/Scala/Python等至少一门编程语言，具有1年以上开发经验；
3、理解分布式数据处理技术原理，有Hadoop或Spark开发经验优先；
4、熟悉Docker、Kubernetes及微服务的应用开发设计优先；
5、熟悉自动驾驶及相关的LiDAR、Camera等传感器数据优先；
6、对技术有强烈的兴趣，喜欢钻研，具有良好的学习和沟通能力。									
									
									
									
									
									
									
									
									
KafkaHadoopFlinkJavaScalaSparkHbaseHDFS
工作职责
1. 负责设计和实现面向智能驾驶业务的云原生大数据计算引擎；
2. 负责将大数据计算和机器学习有机结合，赋能智能驾驶数据闭环；
3. 负责大规模高精度地图生产并行化和智能化研发；
4. 负责对海量车端数据进行智能化和自动化场景识别和挖掘；
5. 负责云原生数据编排和加速引擎，加速分布式模型训练和推理。
任职要求
1. 本科及以上学历，至少2年以上相关工作经验；
2. 掌握Java/Golang/C++其中至少一种，熟练掌握Shell/Python其中至少一种脚本语言，具备良好的面向对象和函数式编程思想，了解常用设计模式；
3. 熟悉Spark、ElasticSearch、Flink、Kafka、Trino、Hadoop、Alluxio等常用组件的使用，了解至少一种组件的实现原理，熟悉分布式系统架构基本理论；
4. 具有大数据计算和AI模型训练/推理结合的经验；
5. 对云原生大数据平台、存储加速、Kubernetes等有使用和研究经验者优先；
6. 对地理信息系统（GIS）、高精地图生产有使用和研究经验者优先；
7. 具备良好的沟通及协调能力、团队合作、责任心。									
									
									
									
									
									
									
									
									
PythonSQLShellScalaSparkFlumeKafkaHadoop
高级数据分析师\数仓（3w-6w）
职责：
1.帮助业务部门分析业务情况，根据实际建立数仓，解决业务数据问题
2.打通原有数据孤岛，建立融合数据体系
3.指导培训工程师，持续提升团队能力
要求
1.本科以上学历，计算机，数学，统计等相关专业；
2.熟悉常用的数仓建模理论，可独立把控数据模型设计；
3.熟悉Hive-sql，Spark-sql，Flink-sql等常用Sql技能；
4.熟悉Shell、Python、R或其他脚本语言中一种或多种；
5.对统计，概率论，算法有一定了解；
6.有良好逻辑思维能力和数据分析能力，善于分析和解决问题
7.有通过数据项目推动产品或运营提升经验优先
数据分析师\数仓（1.5w-3w）
职责：
1.帮助业务部门分析业务情况，根据实际建立数仓，解决业务数据问题
2.打通原有数据孤岛，建立融合数据体系
要求
1.本科以上学历，计算机，数学，统计等相关专业；
2.熟悉常用的数仓建模理论；
3.熟悉Hive-sql，Spark-sql，Flink-sql等常用Sql技能；
4.熟悉Shell、Python、R或其他脚本语言中一种或多种；
5.对统计，概率论，算法有一定了解；
6.有良好逻辑思维能力和数据分析能力，善于分析和解决问题									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
数仓建设经验数据治理经验
工作职责
负责金融大数据治理流程机制的建立；
负责金融大数据治理整体方案的规划设计以及方案落地实施，包括数据标准，元数据，数据质量，数据安全， 指标管理，数据资产管理等；
负责数据架构演进方向，持续提升数据质量，数据研发效率，数据易用性；
工作要求
1、本科以上学历，数学，计算机等相关专业；
2、6年以上数据治理相关工作经验，有0-1大中型企业数据治理体系建设经验；
3、精通数据仓库体系，并支撑过实际业务场景；
3、精通数据标准，元数据，数据质量，指标管理方法论，并有落地经验；
4、思路清晰，有良好的沟通能力和沟通能力，较强的学习能力以及快速解决问题的能力									
									
									
									
									
									
									
									
									
SQLScalaJava大数据开发经验广告业务数仓开发
岗位职责：
1、参与广告数据体系及数据质量建设，包括但不限于数据采集及处理、数仓建设、数据治理、及BI类工作；
2、精准理解业务产运研数据需求，通过数据赋能，支持业务问题的提升和改善；
3、参与数据效能建设，协同大数据基础团队，识别和解决业务数据开发的卡点问题，提升数据效能及质量；
岗位要求：
1、3年以上互联网工作经验，计算机、数学相关专业；
2、熟悉广告业务数据分析常见指标，主导过广告业务专项数据建设；
3、扎实的编程基础，熟练掌握Java、scala语言，具备扎实的数学、数据结构和算法基础；
4、精通SQL、FlinkSQL、HiveSQL等数据处理技术，熟悉python/R，有数据治理相关经验者优先；
5、有数据仓库或实时数据开发经验，熟悉离线、实时数据处理框架如spark/flink；
6、有较强的数据分析思维，有良好的沟通能力和团队合作精神，熟悉产品运营工作；									
									
									
									
									
									
									
									
									
智慧建筑数据仓库数据建模
工作职责：
1.负责智慧建筑平台数据仓库搭建工作
2.设备数据、业务数据入仓、满足业务统计需求和业务人员自主分析需求
3.历史数据对外提供需求。
4.用户行为数据统计分析。
5.基于设备数据以及业务数据进行数据挖掘。
6.负责大数据组件选型以及调优，支持横向扩展，以及资源动态调度。
7.满足即席查询需求。
岗位要求
1.本科以上学历，计算机、软件工程及相关专业； 2.具有5年以上大数据领域工作经验，具备至少5个大中型数据平台项目的架构设计、模型设计、ETL设计与优化的成功案例； 3.熟悉数据治理和数据平台等相关理论知识，有元数据管理、数据质量管理平台建设经验者优先； 4.熟悉数据湖、数据仓库、数据挖掘等大数据相关技术，包含但不限于Hadoop、MapReduce、Hive、Spark、Storm、Flink、Kafka、Datax、Kettle； 5.具备智慧建筑数据平台建设经验优先。									
									
									
									
									
									
									
									
									
JavaPythonShell
岗位职责：
1.	负责集团仓库/指标/BI数据开发工作，负责数据开发团队的管理。
2.	负责标签体系建设，包括模型设计、开发、优化等；
3.	主动将数据资产赋能到业务侧，并能取得业务成果和认可。
岗位要求：
1.	全日制本科及以上学历，10年以上IT经验，6年以上数据行业经验，4年开发经验，必须带过10人以团队。
2.	熟悉数据仓库，数据开发方法论。熟悉数据仓库和数据集市的框架结构，具备数据仓库与数据集市的设计、开发实施能力；
3.	Hadoop生态下能熟练使用SQL，熟悉Hadoop/Spark/Hive原理，对数据敏感，具备较好的数据分析意识，具备数据驱动业务的能力；									
									
									
									
									
									
									
									
									
JavaHbaseSpark计算机相关专业大数据处理经验大数据平台架构经验
工作职责:
1.参与腾讯云大数据智能运维平台建设，负责外部数据对接、数据实时采集、数据加工计算、数据质量监控等工作，建设自动化运维工具来提升运维效率
2.参与大数据智能诊断体系建设，参与基于大数据组件管理关系构建大数据组件智能诊断体系
岗位要求:
1.本科以上学历，5年以上大数据或大数据运维研发经验
2.熟练掌握一门以上开发语言（java/go/python/shell等），熟悉Linux和主流开发框架
3.对大数据生态圈有了解，熟悉HDFS、YARN、Hive、HBase、Elasticsearch、Clickhouse、Flink、Spark、impala等大数据技术，至少精通其中2项以上；
4.熟悉常见运维开源系统以及开源监控系统如Zabbix、Prometheus等，对时序数据库druid\influxdb有使用经验，有大数据运维自动化&智能化，运营支撑系统等开发经验者优先；
5.对异常的智能分类与智能问答有了解,有知识图谱使用经验优先
6.强烈的责任心，优秀的沟通表达与组织协作能力									
									
									
									
									
									
									
									
									
数仓建设经验数据安全
工作职责：
1、负责公司互联网业务的数据治理工作，包括数据安全、数据资产方面的数据治理工作，保障数据资产安全、风险可控；
2、深入数据开发和数据管理业务，制定并推进数据治理解决方案落地实施；
3、负责数据治理相关的标准、流程和规范制定。
任职要求：
1、五年及以上工作经验，至少熟练使用Hive、Spark、Flink等大数据工具中的一种；
2、熟悉数据仓库建设方法论和建设过程，有PB级互联网数据仓库建设经验优先；
3、抗压能力强，有良好的团队合作及协调沟通能力；
4、有大型互联网业务数据安全或资产治理相关经验优先，包括但不限于标准制定、流程建设、智能工具建设等。									
									
									
									
									
									
									
									
									
PythonHIVE
工作职责：
1 根据项目具体要求,完成数据迁移 数据清洗 等相关工作;
2 根据业务数据需求 将数据分层 按照业务逻辑进行数据建模，并及时响应数据提取需求；
3 按照项目需求分析指标逻辑 开发和分析数据指标
4 日常维护集群合理运行，重要参数调优
任职资格：
1 本科及以上学历  计算机相关专业  2年以上数据开发经验 
2 有良好得sql设计编写能力和 sql优化经验
3 精通 shell 脚本 python脚本至少一门脚本语言 具备脚本优化经验
4 熟悉hadoop/hive/spark/hbase 等大数据处理框架技术
5 熟悉数据建模以及etl整体设计开发，对数据仓库，数据中台有一定理解
6 具备海量数据加工处理和优化经验 有olap相关经验者优先
7 优秀得自我驱动你能力和责任心，良好得沟通表达能力和团队协作精神。									
									
									
									
									
									
									
									
									
Spark流式处理
岗位职责
1、负责设备物联网数据解析以及存储。
2、负责用户行为统计分析
3、离线与实时计算平台分析模型的开发；
4、参与公司大数据处理方向的技术拓展
任职资格
1、五年以上开发经验，两年以上基于Hadoop/Kafka/Kudu/Impala/Flink/spark等应用开发经验,对分布式计算有较为深刻的理解
2、熟悉Hadoop技术体系,有Hadoop计算集群在实际项目上的开发和维护经验
3、熟悉Linux/UNIX。
4、了解敏捷开发流程, 有敏捷开发经验者优先
5、虚心好学,思维敏捷,良好的沟通能力和团队精神									
									
									
									
									
									
									
									
									
PythonScalaSparkHadoopFlink
岗位职责：
1. 负责复杂业务场景下数据体系构建，赋能业务数字化运营，保障数据的质量和数据生产的稳定性；
2. 负责基于大数据技术平台基础上的数据仓库建设，包括数据模型设计、离线/实时计算、性能优化以及相关技术问题的解决；
3. 负责数据质量、稳定性、数据资产管理等数据治理工作，构建全链路数据质量监控治理体系；
4. 参与数据产品的需求沟通、架构设计、数据开发以及系统优化。
任职要求：
1. 扎实的代码编程能力，具备良好的数据结构基础，熟悉常见设计模式，熟练使用Java/Scala/Python等至少一种语言；
2. 熟练掌握Hadoop生态，包括但不限于Hive/Spark/Flink等一种或几种大数据计算框架；
3. 熟悉数仓原理和实施，有实时数仓、离线数仓设计与开发经验；
4. 熟悉SpringCloud，SpringBoot等常用的开源框架优先
5. 熟悉OLAP平台建设或有过经验、熟悉业务指标设计且熟练掌握OLAP的维度建模设计方法优先
6. 熟悉常见数据挖掘、用户画像、搜索推荐、知识图谱、自然语言理解等相关算法及模型优先									
									
									
									
									
									
									
									
									
FlinkSpark大数据开发经验
1、负责推荐、搜索、广告等业务场景的数据处理任务开发和调优，保障任务高效稳定运行。
2、负责特征、样本等数据存储结构设计和存储组件选型，提升数据存取速度，降低数据存储成本。
3、负责一站式机器学习数据开发平台建设，整合机器学习相关的数据处理、样本加工、模型训练等环节。
【岗位要求】
1、熟练掌握JAVA语言，熟悉python者优先
2、在推荐、广告或搜索等领域有3-5年以上的数据处理、开发经验
3、熟练掌握flink、spark等大数据开发框架，熟悉kafka、hdfs、Hbase、Iceberg等组件
4、主导过大型数据平台建设、具有机器学习平台化相关经验、具有特征工程相关经验者优先
5、责任心强，积极主动，有良好的沟通能力和团队合作能力									
									
									
									
									
									
									
									
									
大数据开发经验数仓建设经验计算机相关专业
岗位职责：
1. 负责复杂业务场景下数据体系构建，赋能业务数字化运营，保障数据的质量和数据生产的稳定性；
2. 负责基于大数据技术平台基础上的数据仓库建设，包括数据模型设计、离线/实时计算、性能优化以及相关技术问题的解决；
3. 负责数据质量、稳定性、数据资产管理等数据治理工作，构建全链路数据质量监控治理体系；
4. 参与数据产品的需求沟通、架构设计、数据开发以及系统优化。
任职要求：
1. 有数据开发团队管理经验，扎实的代码编程能力，具备良好的数据结构基础，熟悉常见设计模式，熟练使用Java/Scala/Python等至少一种语言；
2. 熟练掌握Hadoop生态，包括但不限于Hive/Spark/Flink等一种或几种大数据计算框架；
3. 熟悉数仓原理和实施，有实时数仓、离线数仓设计与开发经验；
4. 熟悉SpringCloud，SpringBoot等常用的开源框架优先
5. 熟悉OLAP平台建设或有过经验、熟悉业务指标设计且熟练掌握OLAP的维度建模设计方法优先
6. 熟悉常见数据挖掘、用户画像、搜索推荐、知识图谱、自然语言理解等相关算法及模型优先									
									
									
									
									
									
									
									
									
Hive大数据平台架构经验计算机相关专业数学/统计相关专业
职责描述：
1、负责互联网数据分析产品的规划与产品设计；
2、深入理解数据分析的业务全流程，将分析思路转为平台化解决方案；
3、对业务需求有深刻洞察，不断优化埋点相关工作，提高各团队沟通与协作效率；
4、挖掘AB实验流程痛点，通过持续的产品改进提升业务实验效率和用户体验；
5、致力于通过数据产品、数据服务提升公司整体运营效率。
任职要求：
1、大学本科及以上学历；
2、对分析平台、AB实验、埋点等数据产品有比较深入的了解；
3、具有优秀的沟通和团队合作能力，擅于表达和沟通，能主动推进协作团队各项工作有序进展；
4、良好的洞察能力和数据敏感度，善于从日常体验和数据逻辑推理中发现问题，并快速定位到问题根源。
									
									
									
									
									
									
									
									
									
SparkFlinkJava计算机相关专业大数据开发经验数仓建设经验
工作职责：
1. 负责大数据平台的基础环境搭建与性能优化；
2. 负责大数据平台的多信息源数据采集，转换，存储，展示；
3. 负责大数据平台各组件的线上问题排查，保障平台稳定运行。
任职要求：
1. 本科及以上学历，至少5年以上相关工作经验；
2. 掌握Java/Scala其中至少一种，具备良好的面向对象和函数式编程思想，了解常用设计模式；
3. 熟悉Hadoop、Hive、HBase、Spark、Flink、Kafka等常用组件的使用，了解至少一种组件的实现原理；
4. 熟悉分布式系统的基本理论，有大数据平台的架构设计、开发和调试经验；
5. 对时序数据库OpenTSDB、InfluxDB、Druid、Beringei等有使用和研究经验者优先；
6. 具备良好的沟通及协调能力、团队合作、责任心。
7. 对自动驾驶行业有一定了解，并有志于此。									
									
									
									
									
									
									
									
									
HbaseKafkaHive数仓建设经验实时开发
岗位要求：
1、5年以上大数据项目架构/开发/调优经验，具有电商行业数据平台数据架构和开发工作经验优先； 
2、熟悉数据治理、数据质量管理体系，有实际业务落地经验优先； 
3、熟悉常见的算法和数据结构，熟练设计数据模型、ETL设计、Cube多维建模、OLAP开发等； 
4、熟练使用大数据处理框架（Hadoop/Hive/Spark/Kylin）相关技术； 
5、熟悉流式计算引擎，对相关框架(Kafka/Storm/SparkStreaming/Flink)熟悉了解，有实际应用经验优先； 
6、熟悉Linux/Unix系统，精通至少一门编程语言PHP/Python/Java等；熟悉TDW优先；
7、沟通主动，有较强的工作激情和抗压能力，能组织协同团队开发。
岗位职责：
1、负责私域电商业务的离线和实时数据仓库建设，搭建和完善各业务模块的数据指标和报表体系；
2、负责私域电商业务相关的数据分析工作，配合数据产品经理，进行产品和运营核心策略的分析建模； 并协助搭建用户画像体系；
3、跨团队沟通和协作，确保项目顺利推进。									
									
									
									
									
									
									
									
									
Flink计算机相关专业大数据开发经验dorisclickhousepresto
工作职责：
1、负责公司大数据平台、指标体系建设等应用平台的架构、设计、开发
2、支持千亿级数据量上的秒级别的交互分析场景，高效支撑广告/实验平台/用户行为分析等业务场景
3、和团队探索前沿技术，落地和推广实时湖上数据分析、流批统一等场景
岗位要求：
1、计算机或相关专业本科以上学历，5年以上大数据相关工作经验；
2、熟悉Java/go/c++语言，精通SQL，熟悉常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验；
3、熟悉flink、presto、clickhouse、doris等架构与底层实现有深入理解，并有一定的开发、调优、运维经验；
4、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力；									
									
									
									
									
									
									
									
									
SQL银行数据仓库大数据
银行数据开发&建模
 
职位描述
1. 参与蚂蚁银行数据体系的规划建设，包括统一的离线／实时数据架构、公共数据层建设；
2. 参与蚂蚁银行数据产品及应用的数据研发，发掘数据商业价值，打造数据产品，赋能业务部门运营的智能化、风控的实时化；
3. 全面了解互联网金融行业数据，通过大数据技术实现个人用户和小微企业的本质属性实时和全面的刻画，提升用户洞察的能力。
 
 
岗位要求
1.二年以上银行数据仓库或数据集市的工作经验，具有整体架构及核心模块的工作经验；
2.熟悉数据仓库模型、业务敏感度高、熟悉ETL流程，有较强的SQL编写能力；
3.熟悉大数据技术体系，有流式数据处理fflink/storm/spark streaming经验优先，熟悉java应用优先；
4.具有良好的沟通、团队合作精神、敬业精神，能够快速推动工作执行落地；
5.具有快速学习能力，具有银行工作经验者优先									
									
									
									
									
									
									
									
									
SparkHive
岗位职责:
1、承接业务团队离线计算、实时计算需求，对外提供稳定、高效的数据服务；
2、负责实时流服务平台、实时数仓的规划、设计、研发和落地；
3、保持技术前瞻性，持续推动实时系统架构的行业先进性；
4、针对具体的业务场景问题，快速设计和实现解决方案；
5、负责工程架构相关新技术方向研究、开发和应用。
任职要求:
1、本科及以上学历，计算机相关专业，6年以上的spark、Flink等相关研发经验；
2、熟悉spark、Flink原理、深入研究底层技术，具有很强的实际问题解决能力；
3、掌握MapReduce系列大数据系统原理，熟练使用HDFS、Hive，Spark，Flink，HBase，Kafka等分布式计算系统，并对于使用场景，优化方式有着深入理解；
4、有数据中台或应用中台设计开发经验者优先；
5、具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题。									
									
									
									
									
									
									
									
									
分布式技术JavaPythonShell
工作职责：
1.构建大规模分布式大数据服务平台，包括海量多媒体数据存储、离线/实时计算、数据分析和数据挖掘；
2.针对各种业务增长和业务需求，设计、部署、调优大数据组件；
3.参与软件工程系统的设计、开发，编写软件说明书 ；
4.跟踪行业动态，引入新的技术组件，推广新技术应用。
能力要求：
1.计算机科学/自动化控制相关专业，本科及以上学历，5年及以上平台架构经验；
2.具有大规模分布式系统设计、开发、维护经验，有故障处理能力；
3.精通一个及以上的常用开源分布式系统，包括Hadoop/Hive/Spark/Flink/HBase/Kafka/ElasticSearch；
4.精通Shell/Python/java中至少一种语言；
5.对海量存储、性能调优、平台可靠性有深入研究；
6.良好的沟通能力和团队合作精神；
7.快速学习掌握新技术。
加分项：
1.精通实时大数据处理系统；
2.有业务架构经验；
3.有数据安全架构经验；
4.开源工具社区开发经验；
5.英文文档阅读能力。									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
HIVEJava大数据开发经验ScalaHadoopKafkaSparkFlink
【岗位职责】
1. 基于Flink构建统一的流数据平台，支撑数据集成，实时应用开发；
2. 负责数据采集和实时计算平台的设计、开发、维护与优化；
3. 负责实时指标计算的数据建模、架构设计与开发；
4. 参与大数据应用规划，为数据产品、挖掘团队提供应用指导。
【任职要求】
1. 本科及其以上学历，计算机相关专业；
2. 精通Java/Scala语言，如并发编程和JVM等，追求高标准的工程质量；
3. 对Flink，Spark等流式计算框架有深入理解；在Flink方面有丰富经验优先；
4. 熟悉Hive，Hadoop、Kafka、ZK、Elasticsearch、Redis等的工作原理；
5. 熟悉常用算法和数据结构，熟悉网络编程、多线程编程技术；
6. 逻辑清晰，思维敏捷，思路严谨，能独立分析和解决问题，责任心强，具备良好的团队协作能力；
7. 具有较强的学习能力、自我管理能力、敢于挑战。									
									
									
									
									
									
									
									
									
HiveSparkKafka大数据平台架构经验大数据处理经验数仓建设经验prestodorisflink
工作职责：
1、负责公司大数据平台、指标体系建设等应用平台的架构、设计、开发
2、支持千亿级数据量上的秒级别的交互分析场景，高效支撑广告/实验平台/用户行为分析等业务场景
3、和团队探索前沿技术，落地和推广实时湖上数据分析、流批统一等场景
岗位要求：
1、计算机或相关专业本科以上学历，5年以上大数据相关工作经验；
2、熟悉Java/go/c++语言，精通SQL，熟悉常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验；
3、熟悉flink、presto、clickhouse、doris等架构与底层实现有深入理解，并有一定的开发、调优、运维经验；
4、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力；									
									
									
									
									
									
									
									
									
PythonHadoopjava
负责金融业务实时需求的沟通与方案设计；
负责金融业务大数据实时计算开发，实时数仓建设；
负责实时系统的异常数据实时监测和数据质量保障；
岗位要求：
8年以上工作经验，计算机或相关专业本科及以上学历；
熟悉大数据生态组件，包括Hadoop、Hive、Spark、Storm、Flink等
熟练使用Flink，并且对Flink的底层原理有很深的理解，且有5年及以上实时计算开发经验
熟悉linux开发环境，熟练掌握java/python语言开发；
有较强的逻辑思维能力，思想上开放，主动积极有责任感，抗压能力强；									
									
									
									
									
									
									
									
									
ShellSparkHadoopSqoopHIVE
职位描述
岗位职责：
1.负责团队大数据集市的设计与开发，及相关运维工作
2.为算法模型和大数据产品提供数据支撑，以及责解决开发过程中的技术问题
岗位要求：
1.计算机及相关专业毕业，本科学历至少工作两年以上
2.精通Hadoop生态及相关的各种组件，并具备两年以上实战经验，包括但不限Hadoop、Hive、Sqoop、Spark等
3.精通数据数据仓库、数据集市的设计与开发，并且有两年以上的项目经验
4.熟练应用Linux系统，并能熟练编写Shell编程"									
									
									
									
									
									
									
									
									
SQLPythonShellSparkHIVEuplift
岗位说明：
1.基于顺丰大数据的智能营销算法研发。智能营销算法进行建模，包括优惠券模型，预测模型的研发和测试。
2.智能营销项目效果的落地实施，模型自身指标测试，与业务团队共同进行AB效果测试。
3.对模型进行定时升级迭代。
4.帮助部门达成智能营销利润目标。
任职要求：
1.熟悉大数据工具平台hive sql，pyspark,自动化任务调度.
2.熟悉python语言，及机器学习模型开发，熟悉lightgbm，xgboost，回归，分类等工具包使用。
3.了解一种深度学习框架如pytorch，tensorflow等。
4.有点击率模型，时序预测模型研发经验，了解线性规划算法原理。
5.熟悉特征工程，对数据特征有较强的敏感度。
6.有2-3年智能营销项目研发经验。									
									
									
									
									
									
									
									
									
HadoopFlinkKafkaSparkHIVEHbaseJavaDruid
岗位职责：
1.负责Hadoop、Spark、Kafka等大数据系统的搭建、维护、性能优化和演进；
2.负责实时计算平台的开发、维护和演进；
3.负责数据治理系统的开发、维护和演进；
4.负责大数据安全框架的搭建和维护；
岗位要求：
1.熟悉Java、熟悉网络编程和多线程编程技术，熟悉常见的数据结构和算法；
2.熟悉linux 台, 熟悉至少一种脚本语言(shell/python) ;
3.熟悉Hadoop、Spark、Kafka等大数据系统；
4.有SparkStreaming、Flink等流式计算框架开发经验优先；
5.有Datahub、Atlas等元数据管理系统开发经验优先
6.有Ranger、Kerberos等大数据安全组件开发经验优先；									
									
									
									
									
									
									
									
									
数据仓库
岗位职责：	
分布式大数据系统开发、计算性能调优、 高性能服务框架设计与开发； 
参与项目的架构设计、评审、技术攻坚及优化； 
参与系统文档的撰写、维护。
岗位要求：	
本科以上学历，计算机或相关专业；
 3年以上Linux后台开发经验，有大规模系统开发经验；
 熟悉Python/R/SAS/等数据分析工具；
 具有Hadoop/Spark/Hbase/impala/druid等分布式计算平台的使用和一定性能优化经验；
 熟悉mysql/PG/oracle等数据库使用和一定SQL优化经验；
 熟悉常用大数据开源组件；
 有高并发、大容量后台服务系统设计经验；
 具有良好的学习能力、沟通能力、团队合作意识；
 强烈的责任心与主动性，对所负责工作有owner意识，并能自我驱动成长									
									
									
									
									
									
									
									
									
HiveSparkFlink计算机相关专业大数据开发经验数仓建设经验
负责部门数据治理及BI数据建设相关工作，负责BI报表数据开发，运营数据诊断，链路分析，监控工具的建设， 负责部门内外底层数据及各数据平台的对接工作和部门内整体数据质量的优化工作。为数据的质量、准确性、及时性和稳定性以及线上问题解决的效率负责。
岗位要求
1、熟悉Hive,Hadoop,HDFS,Mapreduce,Yarn的原理，熟练使用spark,flink等大数据开发技术
2、有良好的数仓建设能力，对数仓分层，数据建模方面有深刻理解，能够从数据采集，计算和应用全流程进行保障和改进；
3、熟悉Linux操作系统，熟悉数据库的基本原理，熟练使用JAVA,python 等语言，掌握常见的消息队列，缓存相关技术
4、有海外数据业务开发经验，有亚马逊,appsflyer,adjust使用经验者优先
5、有良好的沟通能力和协作精神，勇于承担工作压力									
									
									
									
									
									
									
									
									
PythonScalaSparkHadoopHIVESQLFlink
数据平台开发高级工程师 (T8/T9)
【职位描述】
    1、负责风控数据仓库的建设，包括数仓以及相关数据应用的数据模型设计、开发、运营。
    2、负责风控数据治理，包括数据质量监控和管理、ETL任务性能优化、元数据管理等。
    3、负责风控数据平台建设，包括数据接入系统、元数据管理系统、数据质量管理系统等。
    4、参与风控风险模型设计、开发、分布式部署等。
【职位要求】
    1、计算机/数学相关专业，有3年以上的数据仓库建设、数据治理经验。
    2、对hadoop、hive、spark等大数据基础技术有透彻的理解，有spark应用开发经验。
    3、精通SQL、Scala、Python、Java等中的至少两种编程语言，并有良好的编码习惯。
    4、有一定的机器学习建模经验。
    5、具有良好的学习能力、沟通技能，具备空杯心态，有较强的团队合作精神和责任心。
【加分项】
    1、有数据平台元数据管理、数据质量监控研发经验者优先。
    2、有大数据分析/BI/OLAP后台系统研发经验者优先。
    3、有数据可视化经验者优先。
    4、有flink/sparkstreaming实时计算相关经验优先
【工作年限】
    3年以上									
									
									
									
									
									
									
									
									
SQLHiveSpark计算机相关专业大数据开发经验数仓建设经验看中学习能力关注稳定性
【职位描述】
    1、负责风控数据仓库的建设，包括数仓以及相关数据应用的数据模型设计、开发、运营。
    2、负责风控数据治理，包括数据质量监控和管理、数据ETL、元数据管理等。
    3、负责风控数据平台建设，包括数据接入系统、元数据管理系统、数据质量管理系统等。
【职位要求】
    1、计算机/数学相关专业，有3年及以上的据仓库建设、数据治理经验。
    2、精通SQL、Python、Scala、Java等中的至少两种编程语言，并有良好的编码习惯。
    3、对hadoop、hive、spark等大数据基础技术有透彻的理解，有spark应用开发经验。
    4、细心、积极、主动，具备优秀的团队合作、精益求精的精神，良好的沟通协调能力。
【加分项】
    1、有主动识别数仓建设、数据治理中存在的问题、并配合制定优化整改方案的能力者优先。
    2、有数据平台元数据管理、数据质量监控研发经验者优先。
    3、有大数据性能优化经验者优先。
    4、有flink/sparkstreaming实时计算相关经验优先。
【工作年限】
    3年及以上									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
PythonSQLSparkStreamingFlink
业务介绍
依靠数据和技术驱动金融业务运营，打造新型东南亚数字银行，应用云计算，大数据，人工智能等互联网技术，着力在服务模式，客户群体，风控制度等领域进行创新。为东南亚广大用户提供更加贴近生活，简单易用的存款，贷款，转账，理财等金融基础服务。
岗位职责
负责银行数据仓库的系统建设和金融业务的数据组件调研、设计
负责实时应用、数据治理平台、数据服务等组件的研发工作
负责搭建数据治理体系和推进相关工具的落地，包括但不限于数据血缘关系管理，作业依赖关系解析，SQL性能分析等
 
岗位要求
3年及以上开发经验；
本科（全日制）及以上学历，理工科类专业
熟悉大数据计算平台架构，掌握Spark Streaming、Structured Streaming、Flink，有实时项目开发经验更佳
具有扎实的编程功底，熟悉常用的算法和数据结构，精通Java/Python编程语言，有分布式计算应用开发更佳
具有良好的团队合作和沟通能力，有很强的自驱力，能主动为结果负责
有良好的业务理解, 掌握一定的数据质量方法论、数据治理方法论等									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
JavaScalaSparkHadoopStormStreamingFlink
岗位职责：
   负责公司级平台的数据清洗以及数据分析
   
   
岗位要求
- 本科及以上学历，扎实的计算机专业基本功，编程基础扎实，对代码质量有追求;
- 2年以上scala开发经验，熟练使用scala开发spark任务
- 熟悉常见设计模式，熟悉Spring，SpringMVC,Springboot,SpringCloud ,MyBatis等流行开源框架，深入了解其原理和实现机制;
- 精通MySQL应用开发，熟悉数据库原理和常用性能优化技术，以及NoSQL、Queue 的原理、使用场景以及限制;
- 熟练掌握大数据处理技术栈优先，有丰富的Hadoop/Spark/SparkStreaming/Storm/Flink的实际项目使用经验。
- 能够独立或协同，高质量按期完成项目;
- 有较强的逻辑思维能力，善于分析、归纳、解决问题，持续学习和总结，自我迭代									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
JavaPythonShell大数据开发经验
岗位职责：
1、负责私域电商业务的离线和实时数据仓库建设，搭建和完善各业务模块的数据指标和报表体系； 2、负责私域电商业务相关的数据分析工作，配合数据产品经理，进行产品和运营核心策略的分析建模； 并协助搭建用户画像体系； 3、跨团队沟通和协作，确保项目顺利推进。
岗位要求：
1、5年及以上大数据项目架构/开发/调优经验，具有电商行业数据平台数据架构和开发工作经验优先； 2、熟悉数据治理、数据质量管理体系，有实际业务落地经验优先； 3、熟悉常见的算法和数据结构，熟练设计数据模型、ETL设计、Cube多维建模、OLAP开发等； 4、熟练使用大数据处理框架（Hadoop/Hive/Spark/Kylin）相关技术； 5、熟悉流式计算引擎，对相关框架(Kafka/Storm/SparkStreaming/Flink)熟悉了解，有实际应用经验优先； 6、熟悉Linux/Unix系统，精通至少一门编程语言PHP/Python/Java等；熟悉TDW优先； 7、沟通主动，有较强的工作激情和抗压能力，能组织协同团队开发									
									
									
									
									
									
									
									
									
JavaHiveSpark大数据开发经验数仓建设经验ETL开发经验
岗位职责：1、负责风控数据仓库的建设，包括数仓以及相关数据应用的数据模型设计、开发、运营。 2、负责风控数据治理，包括数据质量监控和管理、数据ETL、元数据管理等。 3、负责风控数据平台建设，包括数据接入系统、元数据管理系统、数据质量管理系统等。
岗位要求：1、计算机/数学相关专业，有3年以上的据仓库建设、数据治理经验。 2、精通SQL、Python、Scala、Java等中的至少两种编程语言，并有良好的编码习惯。 3、对hadoop、hive、spark等大数据基础技术有透彻的理解，有spark应用开发经验。 4、细心、积极、主动，具备优秀的团队合作、精益求精的精神，良好的沟通协调能力。 【加分项】 1、有主动识别数仓建设、数据治理中存在的问题、并配合制定优化整改方案的能力者优先。 2、有数据平台元数据管理、数据质量监控研发经验者优先。 3、有大数据性能优化、TroubleShooting经验者优先。 4、有flink/sparkstreaming实时计算相关经验优先。									
									
									
									
									
									
									
									
									
SparkPython
腾讯运营超大规模系统，随之而来带来了百万级机器实例，云存储、云数据库等超大规模运营性挑战。在这里，你有机会理解这些挑战，和大牛们一起进行创新性的思考，以产品化、平台化的方式，结合云原生等科技，站在行业视角来解决大规模系统运营挑战。超大规模系统产生了PB级别数据，理解、分析、和解释这些数据是迈向智能化运维的基础。在这里，你将要挑战最新的数据仓库架构，超大规模数据挑战，超大规模模型训练等；为技术产品赋能。
- 以高级数据开发工程师的身份参与到整体数据平台建设，主导PB级别数据中台建设；
- 与产品、开发、运维、测试相关团队紧密协作；持续理解、改进超大规模运营产品的自动化和智能化挑战；
- 以统一基础设施为基础，建设统一数据标签、规范，建立集中式PB级别数据采集、加工、存储、和处理平台；
- 建设统一数据分析和训练平台，与业务方共建，以数据赋能业务；
- 以生态化的方式参与开源社区建设，影响开源项目发展。
工作要求
- 统招本科及以上学历，计算机或相关专业，善于与他人合作，学习能力强；
- 3 年以上大规模数据中台建设经验，熟悉Apache Hudi/Iceberg/Spark/ClickHouse 者优先；
- 有开源经验者优先，有业界知名相关数据类开源项目经验者优先。
北京/深圳可选									
									
									
									
									
									
									
									
									
数仓设计/开发经验大数据开发经验SQL
岗位职责：
1、负责公司相关业务数据仓库体系和分析体系建设；
2、结合业务需求场景，制定专业的数据解决方案，解决业务问题，保障业务发展；
3、主导项目内数据研发能力建设，包括服务管理、数据管理、技术架构设计等，能够做好前瞻技术规划。
任职要求：
1、本科及以上学历，5年以上大型数据仓库规划、实施和治理经验；
2、掌握并熟练使用数据仓库的常用架构、常用的数据模型设计方案；
3、具备良好的需求分析、系统分析与设计能力；
4、精通SQL，有一定的SQL性能调优经验，熟悉大数据生态内技术栈；
5、具有较强的业务理解能力，具备强烈的进取心、求知欲及团队合作精神。									
									
									
									
									
									
									
									
									
SQLHbaseFlinkYarnJavaHadoopSparkHIVE
职责描述：
1、负责大数据平台开发工作，包括离线数仓与实时数据的采集、清洗和加工。
2、负责大数据平台数据仓库的建设，基于业务需求开发数据建模。
3、负责大数据平台的日常运维管理，保障数据平台的稳定性。
4、解决大数据平台的重大故障及性能问题，提升数据分析效率。
任职要求：
1、1年以上大数据相关开发经验，具备实时计算或离线数仓经验者优先
2、掌握java或python等任一语言，具备扎实的编程技术基础。
3、精通Hadoop大数据平台框架，精通HDFS系统原理，熟练掌握Flink、Hive、Hbase、Yarn等组件的应用，熟练掌握常用的ETL工具。
4、熟悉Linux操作系统及命令，熟练掌握Shell编程开发。
5、精通SQL，有较丰富的SQL开发经验。
6、具备良好的沟通能力、较强的主动性及责任心。有海量数据系统开发、大数据性能调优经验者优先。
备注：本岗位为荣耀自有员工，非外包。									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
数据仓库ETL数据库开发数据分析PythonJava
1) 负责Lazada数据和应用产品的数据体系的建设，通过数据+算法+工程化能力，不断完善Lazada的数据化运营能力；
2) 参与Lazada数据基础架构和技术体系的规划建设，包括数据处理、数据采集、数据质量及稳定性保障、数据治理、智能化和自动化建设。
3) 作为衔接Lazada数据新加坡团队和集团技术中台的桥梁，加速中台的产品向Lazada的输出。
职位要求：
1) 有从事分布式数据存储与计算平台应用开发经验，有离线计算Hadoop/Spark/ODPS或流计算Storm/Flink的开发经验尤佳；
2) 较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；在数据质量、保障、治理等方面有一定实践经验；
3) 熟悉电商业务相关的业务和技术领域；
4) 具备一定的JAVA/Python语言的开发能力，有机器学习算法能力尤佳；
5) 有较好的英语听说读写能力；
6) 欢迎聪明、乐观、皮实、自省的您！									
									
									
									
									
									
									
									
									
PythonScalaSparkHadoopKafkaHDFSMapReduceHbase
【岗位职责】
负责腾讯游戏内容中台支撑业务的数据开发工作，涉及数据仓库及报表系统；
负责腾讯游戏内容中台自身海量数据的实时计算、离线计算、存储、查询；
参与腾讯游戏内容中台的数据平台自助化建设。
【岗位要求】
计算机相关专业，2年及以上相关工作经验，有扎实的计算机理论基础；
熟练掌握Java、Scala、Python等编程，有良好的编码习惯；
深入理解MapReduce，熟练使用Spark、Hive、Hadoop、Flink或其他大数据工具；
熟练使用HDFS、Hbase、Kafka、ElasticSearch；
具备良好的学习能力、分析解决问题能力，做事细心；
具有高度的责任心和团队合作精神，具备一定的抗压能力；
有前端数据展示开发经验者加分。									
									
									
									
									
									
									
									
									
SQLJavaSparkHadoopHIVEKafkaFlinkDruid
工作职责
1、公司实时数据计算架构方案设计和实现，包括技术选型和落地以及建设方法论沉淀
3、日常实时海量数据处理,确保数据低延时,高可用
4、实时数据仓库建设,在元数据管理、数据安全和数据质量方面有项目经验
5、搭建行业先进互联网大数据基础数据体系，打造稳定高效的数据架构。
任职要求
1、本科及以上学历，计算机、软件、数学统计、通信等相关专业；
2、精通flink编程，熟练使用大数据相关组件(不限于Hive/presto/Spark/es/redis等）
3、熟悉实时数仓生命周期及各类建模理论，有实际互联网实时数仓建设经验者优先；
4、在流式计算、批处理计算引擎，大数据存储和消息队列技术方面有深刻理解；
5、在数据湖方面有落地实施经历，熟悉流批一体化建设者优先；
6、扎实的编程能力，精通java/Scala/python至少一门语言，有元数据管理经验者优先；
7、熟悉OLAP(不限于druid/tidb/clickhouse)相关技术架构和使用场景开发者优先；
8、工作认真负责,优秀的团队精神，抗压能力强，有追求卓越的精神									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
JavaHadoopSparkFlinkKylinHIVEKafkaHbase
岗位职责：
1.负责Hadoop、Spark、Kafka等大数据系统的搭建、维护、性能优化和演进；
2.负责实时计算平台的开发、维护和演进；
3.负责数据治理系统的开发、维护和演进；
4.负责大数据安全框架的搭建和维护；
岗位要求：
1.熟悉Java、熟悉网络编程和多线程编程技术，熟悉常见的数据结构和算法；
2.熟悉linux 台, 熟悉至少一种脚本语言(shell/python) ;
3.熟悉Hadoop、Spark、Kafka等大数据系统；
4.有SparkStreaming、Flink等流式计算框架开发经验优先；
5.有Datahub、Atlas等元数据管理系统开发经验优先
6.有Ranger、Kerberos等大数据安全组件开发经验优先；									
									
									
									
									
									
									
									
									
HiveHIVEKylinFlinkSparkSQLSparkJava
【工作职责】
1. 负责vivo商业化广告核心业务的实时和离线数据开发。
2. 负责广告dmp、商业化报表、策略指标的系统分析与架构设计，配合产品经理完成产品的快速研发与交付。
3. 负责商业化策略和算法特征开发，保障数据质量，配合算法工程师优化模型效果。
4. 负责基于Flink的大规模实时架构开发。
5. 负责相关业务的数据梳理以及流程优化，为团队提供数据支撑。
【岗位要求】
1. 大数据开发3年以上经验，本科以上学历。
2. 熟悉常用大数据开源系统，熟悉Hadoop、Hive、Flink、Spark、Yarn、Kylin、Druid等框架组件一种或多种，理解分布式数据处理技术原理。
3. 熟悉离线数仓的分层设计与主题域建议，熟悉OLAP、BI报表建设，有数据分析或大数据算法经验优先。
4. 具备较强的逻辑思维能力和数字敏感性，具有广告背景优先。
5. 有持续学习新知识能力，抗压力较较强，优秀团队意识。									
									
									
									
									
									
									
									
									
大数据开发经验大数据套件
岗位职责： 
1、负责腾讯云大数据处理套件TBDS产品的服务设计和开发工作； 2、负责全链路大数据开发及数据治理服务设计和开发工作； 3、负责实时流数据处理、离线批数据分析、实时多维分析等高性能数据分析引擎服务开发。
岗位要求： 
1、本科及以上学历，计算机相关专业，3年以上相关工作经验; 2、熟悉 Linux 开发环境，精通Java/Golang/C++一种或多种编程语言 3、扎实的数据结构，算法和编程功底，有良好的编程习惯和风格; 4、精通SQL操作，具有MySQL/Oracle/SQLServer一种或多种关系数据库开发经验； 5、熟悉TCP/IP协议栈，具有TCP/UDP网络编程相关经验; 6、熟悉或使用过Hadoop、HBase、Spark、Hive、Storm、Flink、ElasticSearch等开源大数据套件者优先 7、熟悉或使用过HDFS，Ceph等分布式文件系统者优先 8、熟悉K8S和Docker等容器技术者优先; 9、优秀的分析问题、解决问题能力和团队合作意识、有良好的责任心、善于沟通、工作上能自主驱动、用于接受挑战、富有创新精神; 10、通过腾讯云技术认证或同等资格认证的优先录取 通过腾讯云从业资格证或同等资格认证的优先录取									
									
									
									
									
									
									
									
									
JavaSparkKafkaFlinkHadoop
岗位职责：
1、负责大数据产品的技术研究与架构设计；
2、系统架构设计和优化，对系统业务架构、数据架构、应用架构、技术架构负责
3、主导进行性能、稳定性优化，技术难题攻关。发现并解决各类潜在技术风险
4、研究探索前沿技术，提高软件可用性和开发效率，降低维护成本
岗位KPI：
1、完成大数据组件和技术选型。结合业务架构提出软件架构优化和演进策略。
2、组织并完成性能、稳定性等攻关任务，负责架构设计以及核心代码编写
3、探索前沿技术，完成所在领域的技术积累和团队能力培养。
任职要求：
1、有良好的模型抽象和架构设计能力。能理解复杂的业务需求，抽象并设计合理的技术架构；
2、深入理解大数据存储、大数据计算技术，精通hadoop/spark/flink/kafka/mpp，有海量数据处理实战经验，对高性能和高可靠设计有实战经验
3、熟悉虚拟化、云计算技术，能进行容器化、微服务化系统的架构设计，k8s/docker
4、精通B/S系统架构的相关技术，熟悉J2EE设计模式，熟悉主流应用服务器框架、分布式数据库、缓存、文件系统、消息系统等技术，具备丰富的java前后台开发经验
5、理解机器学习、深度学习算法，能使用一种或多种主流的开源AI框架者优先									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
SQLJava大数据平台架构经验计算机相关专业大数据处理经验
岗位职责
主要负责大数据计算平台的SQL引擎层研发和计算层研发，包括SQL解析、执行计划优化、计算引擎优化、底层服务对接、生态建设等。直接参与对接腾讯多个核心产品线的数据平台体系；
负责研发下一代超大规模云上分布式计算引擎、MPP计算引擎、搜索分析引擎等。打造世界领先的自适应智能混合云计算架构，为云上的核心产品提供重要支持；
负责分析系统瓶颈与架构合理性，促进服务架构优化，参与开源社区的合作。
职位要求
1.熟练掌握Java编程，有深厚扎实的系统知识、系统性能意识，良好的代码能力。
2. 计算机或相关本科及以上学历，在大数据计算和存储相关领域有8年及以上研发经验，并有大规模落地应用者优先。
3. 熟悉Presto/Spark/Hive引擎和相关调度框架，并有复杂ETL开发实践经验。了解业界其他主流的大数据计算引擎，比如Flink。有过深入了解其中几种开源系统核心设计思想、架构、实现，有相关的bug修复经验、性能优化经验、了解源码者优先。
4. 有SQL引擎优化开发，比如Apache Calcite/SparkSQL/Beam等项目经验者优先。熟悉实时湖仓架构和大数据建模方法，了解如何构建计算平台的优先；
5. 熟悉云原生的基础架构，有实际在计算场景中运用主流开源大数据引擎容器化技术，比如 Flink / Spark / Presto /…  on Kubernetes 架构设计和研发工作
6. 工作认真负责，对目标有自驱力，注重技术细节，关注业界和学术界的技术发展趋势。可以独立领导大型系统开发，有良好的团队合作精神，有大数据团队负责人角色经验者优先。									
									
									
									
									
									
									
									
									
PythonJavaSparkHadoopHIVEFlink
1）熟悉一门数据处理语言，如SQL、JAVA、Python、Perl等，了解接触过unix或者linux；
2）具备扎实的专业基础，良好的沟通能力和团队合作，主动积极，乐于面对挑战；
3）参与过数据处理、分析、挖掘等相关项目更好；
4）对Hadoop、Hive、Hbase、Spark、Flink等分布式平台有一定了解更好，如果科研或者横项中使用过那就更棒了；
5）对一些常用分类、聚类等算法，诸如SVM、随机森林、xgboost、GBDT，有所了解更好，如果略微接触过RNN、CNN等那就更棒了。									
									
									
									
									
									
									
									
									
SparkKafkaFlink计算机相关专业数学/统计相关专业大数据开发经验
高级大数据平台开发工程师-实时平台
岗位描述:
1.负责Shopee实时数据平台产品研发如Web SQL IDE、任务管理平台、任务运维平台等；
2.解决项目服务化过程中遇到的技术难点,并对工程中对问题运行拆解和落地;
3.深度参与设计完善系统可用性保障体系，保证系统的长期稳定运行;
4.参与实时计算平台功能规划,开发进度安排,并对功能效果进行总结.
岗位要求:
1.5年及以上使用JAVA开发的经验，基础扎实，理解io、多线程、集合等基础框架。深入了解JVM原理，对Spring,Mybatis等开源框架熟悉；拥抱开源，喜欢阅读开源源码;
2.对实时计算平台产品功能有深入的了解, 对实时计算周边系统Kafka、HBase、Hive等的原理有一定的了解;
3.具有平台规划和实施的实际工作经验;
加分项:
1.深入了解Flink在业务中的使用,并对事实计算场景有深入的总结;
2.对Flink源码有深入了解, 并对Flink Runtime 或者SQL有实际优化经验;
3.深度参与业务实时数仓整体建设,了解分层原理,并有实际数据开发经验;
4.对数据湖技术有深度实践,并进行相关功能开发经验。									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
HiveHIVEKylinFlinkSparkSQLSparkJava
【工作职责】
1. 负责vivo商业化广告核心业务的实时和离线数据开发。
2. 负责广告dmp、商业化报表、策略指标的系统分析与架构设计，配合产品经理完成产品的快速研发与交付。
3. 负责商业化策略和算法特征开发，保障数据质量，配合算法工程师优化模型效果。
4. 负责基于Flink的大规模实时架构开发。
5. 负责相关业务的数据梳理以及流程优化，为团队提供数据支撑。
【岗位要求】
1. 大数据开发3年以上经验，本科以上学历。
2. 熟悉常用大数据开源系统，熟悉Hadoop、Hive、Flink、Spark、Yarn、Kylin、Druid等框架组件一种或多种，理解分布式数据处理技术原理。
3. 熟悉离线数仓的分层设计与主题域建议，熟悉OLAP、BI报表建设，有数据分析或大数据算法经验优先。
4. 具备较强的逻辑思维能力和数字敏感性，具有广告背景优先。
5. 有持续学习新知识能力，抗压力较较强，优秀团队意识。									
									
									
									
									
									
									
									
									
数据仓库ETL数据挖掘SQLJavaHadoopSparkHBase
工作职责：
1. 参与支付、信贷、生活服务等金融业务的数据集市与报表开发，包括多维指标视图加工、用户画像、计算任务管理、元数据构建与维护、数据质量保证等；建设必要的ETL工具组件和平台，提供便捷高效的数据接入、清洗和统计能力；
2. 参与风控、营销、搜索推荐等场景下的实时特征计算和实时多维分析，为业务提供及时准确高效的数据指标和效果跟踪，提升业务转化和产品体验；
3. 与产品和运营团队一起设计和构建准确、完善、深入的指标体系，对数据进行深入分析和洞察，为业务规划和运营提供参考。
任职要求
1. 本科及以上学历，2年以上数据仓库开发经验；
2. 熟练掌握SQL语法，熟悉Hive、Oracle、MySQL常规数据库使用和性能调优技巧，熟悉数据仓库层次模型和数据集市理论，有TB级数据仓库使用经验优先；
3. 熟悉Storm、Spark Streaming、Flink等流式计算框架的使用；
4. 熟悉HBase、Cassandra等常见分布式数据存储读写及其性能优化；
5. 熟悉Kylin、Druid、ClickHouse等OLAP系统的架构和使用场景；
6. 熟练掌握Kafka、Pulsar等消息队列；
7. 较好的业务理解和洞察能力，熟悉支付、信贷、财务等数据分析和模型者优先；
8. 熟悉Python和Shell开发，掌握Java、Scala、Golang等开发语言者优先。									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
JavaHiveSpark大数据开发经验后台开发
工作职责：
1、负责腾讯云大数据处理套件TBDS产品的服务设计和开发工作；
2、负责全链路大数据开发及数据治理服务设计和开发工作；
3、负责实时流数据处理、离线批数据分析、实时多维分析等高性能数据分析引擎服务开发。
岗位要求：
1、本科及以上学历，计算机相关专业，3年以上相关工作经验;
2、熟悉 Linux 开发环境，精通Java/Golang/C++一种或多种编程语言 ；
3、扎实的数据结构，算法和编程功底，有良好的编程习惯和风格;
4、精通SQL操作，具有MySQL/Oracle/SQLServer一种或多种关系数据库开发经验；
5、熟悉TCP/IP协议栈，具有TCP/UDP网络编程相关经验;
6、熟悉或使用过Hadoop、HBase、Spark、Hive、Storm、Flink、ElasticSearch等开源大数据套件者优先 ；
7、熟悉或使用过HDFS，Ceph等分布式文件系统者优先；
8、熟悉K8S和Docker等容器技术者优先;
9、优秀的分析问题、解决问题能力和团队合作意识、有良好的责任心、善于沟通、工作上能自主驱动、用于接受挑战、富有创新精神;
10、通过腾讯云技术认证或同等资格认证的优先录取 通过腾讯云从业资格证或同等资格认证的优先。									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
									
```
